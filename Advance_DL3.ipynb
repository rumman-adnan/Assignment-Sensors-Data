{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rumman-adnan/Assignment-Sensors-Data/blob/main/Advance_DL3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWXISBkTWJsc",
        "outputId": "8fdacad2-754f-47f7-f807-030f0ea6c8a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Load the training and test data\n",
        "train_path = '/content/drive/MyDrive/Python work/sim_data/simu_20000_0.1_90_140_train.npy'\n",
        "test_path = '/content/drive/MyDrive/Python work/sim_data/simu_10000_0.1_141_178_test.npy'\n",
        "train_data = np.load(train_path)\n",
        "test_data = np.load(test_path)\n",
        "\n",
        "# Extract the sensor data and the target variables (S and D)\n",
        "X_train = train_data[:, :1000]\n",
        "y_train = train_data[:, -2:]\n",
        "X_test = test_data[:, :1000]\n",
        "y_test = test_data[:, -2:]\n"
      ],
      "metadata": {
        "id": "-_kOBw_9WQ78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mean = np.mean(X_train, axis = 1)\n",
        "X_train_mean = np.reshape(X_train_mean, (-1,1))\n",
        "X_train_std = np.std(X_train, axis = 1)\n",
        "X_train_std = np.reshape(X_train_std, (-1,1))\n",
        "X_train = (X_train - X_train_mean)/X_train_std\n",
        "\n",
        "\n",
        "X_test_mean = np.mean(X_test, axis = 1)\n",
        "X_test_mean = np.reshape(X_test_mean, (-1,1))\n",
        "X_test_std = np.std(X_test, axis = 1)\n",
        "X_test_std = np.reshape(X_test_std, (-1,1))\n",
        "X_test = (X_test - X_test_mean)/X_test_std"
      ],
      "metadata": {
        "id": "zXsO6Kj4W3w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TCN Algorithm\n",
        "- With Z transform Scaling"
      ],
      "metadata": {
        "id": "fka_FYtlcGsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.metrics import MeanAbsoluteError\n",
        "\n",
        "# Reshape data for TCN\n",
        "X_train = X_train[:, :, np.newaxis]\n",
        "X_test = X_test[:, :, np.newaxis]\n",
        "\n",
        "# Build the TCN model\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(X_train.shape[1], 1)),\n",
        "    layers.Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.GlobalMaxPooling1D(),\n",
        "    layers.Dense(50, activation='relu'),\n",
        "    layers.Dense(2)  # Two output nodes, one for S and one for D\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=[MeanAbsoluteError()])\n",
        "\n",
        "# Train the model for 70 epochs and capture loss after each epoch\n",
        "for epoch in range(70):\n",
        "    history = model.fit(X_train, y_train, epochs=1, batch_size=32, verbose=1)\n",
        "    loss = history.history['loss'][0]\n",
        "    mae = history.history['mean_absolute_error'][0]\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate Mean Absolute Error for S and D separately\n",
        "    mae_s = MeanAbsoluteError()\n",
        "    mae_s.update_state(y_test[:, 0], y_pred[:, 0])\n",
        "    mae_d = MeanAbsoluteError()\n",
        "    mae_d.update_state(y_test[:, 1], y_pred[:, 1])\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {loss}, Train MAE: {mae}, Test Loss: {test_loss}, Test MAE: {test_mae}, MAE for S: {mae_s.result().numpy()}, MAE for D: {mae_d.result().numpy()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0Zbj7qUSZTzZ",
        "outputId": "418d33c5-5ee1-414e-88d6-d9be27e77953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 76s 119ms/step - loss: 900.1751 - mean_absolute_error: 20.4134\n",
            "313/313 [==============================] - 7s 23ms/step\n",
            "Epoch 1, Train Loss: 900.1751098632812, Train MAE: 20.413358688354492, Test Loss: 3886.7744140625, Test MAE: 54.49633026123047, MAE for S: 81.74302673339844, MAE for D: 27.249624252319336\n",
            "625/625 [==============================] - 74s 119ms/step - loss: 212.1102 - mean_absolute_error: 12.3199\n",
            "313/313 [==============================] - 7s 22ms/step\n",
            "Epoch 2, Train Loss: 212.11024475097656, Train MAE: 12.31992244720459, Test Loss: 2137.442138671875, Test MAE: 38.00725173950195, MAE for S: 62.26210021972656, MAE for D: 13.75239372253418\n",
            "625/625 [==============================] - 75s 120ms/step - loss: 172.4822 - mean_absolute_error: 11.2070\n",
            "313/313 [==============================] - 8s 24ms/step\n",
            "Epoch 3, Train Loss: 172.482177734375, Train MAE: 11.206998825073242, Test Loss: 846.1478271484375, Test MAE: 24.299219131469727, MAE for S: 37.57769775390625, MAE for D: 11.020740509033203\n",
            "625/625 [==============================] - 74s 118ms/step - loss: 173.7054 - mean_absolute_error: 11.2601\n",
            "313/313 [==============================] - 8s 24ms/step\n",
            "Epoch 4, Train Loss: 173.70535278320312, Train MAE: 11.26014232635498, Test Loss: 714.7791137695312, Test MAE: 22.419450759887695, MAE for S: 33.94609451293945, MAE for D: 10.892807960510254\n",
            "625/625 [==============================] - 74s 118ms/step - loss: 178.0708 - mean_absolute_error: 11.3930\n",
            "313/313 [==============================] - 6s 19ms/step\n",
            "Epoch 5, Train Loss: 178.0707550048828, Train MAE: 11.393007278442383, Test Loss: 1022.5139770507812, Test MAE: 26.27838134765625, MAE for S: 42.339351654052734, MAE for D: 10.21740436553955\n",
            "625/625 [==============================] - 74s 118ms/step - loss: 176.8201 - mean_absolute_error: 11.3680\n",
            "313/313 [==============================] - 9s 28ms/step\n",
            "Epoch 6, Train Loss: 176.8201446533203, Train MAE: 11.368029594421387, Test Loss: 963.6121826171875, Test MAE: 25.592926025390625, MAE for S: 40.831451416015625, MAE for D: 10.354425430297852\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 177.5631 - mean_absolute_error: 11.3852\n",
            "313/313 [==============================] - 6s 18ms/step\n",
            "Epoch 7, Train Loss: 177.56312561035156, Train MAE: 11.3851957321167, Test Loss: 929.1619873046875, Test MAE: 25.120708465576172, MAE for S: 40.057029724121094, MAE for D: 10.184391021728516\n",
            "625/625 [==============================] - 81s 130ms/step - loss: 176.5108 - mean_absolute_error: 11.3570\n",
            "313/313 [==============================] - 8s 26ms/step\n",
            "Epoch 8, Train Loss: 176.51080322265625, Train MAE: 11.356972694396973, Test Loss: 905.0142822265625, Test MAE: 24.83289909362793, MAE for S: 39.45719909667969, MAE for D: 10.208598136901855\n",
            "625/625 [==============================] - 77s 123ms/step - loss: 176.2710 - mean_absolute_error: 11.3549\n",
            "313/313 [==============================] - 7s 23ms/step\n",
            "Epoch 9, Train Loss: 176.27098083496094, Train MAE: 11.354866027832031, Test Loss: 932.1146850585938, Test MAE: 25.198440551757812, MAE for S: 40.065574645996094, MAE for D: 10.331307411193848\n",
            "625/625 [==============================] - 77s 123ms/step - loss: 178.5095 - mean_absolute_error: 11.4009\n",
            "313/313 [==============================] - 8s 24ms/step\n",
            "Epoch 10, Train Loss: 178.50946044921875, Train MAE: 11.40091323852539, Test Loss: 902.6265869140625, Test MAE: 24.839130401611328, MAE for S: 39.32188034057617, MAE for D: 10.356371879577637\n",
            "625/625 [==============================] - 74s 119ms/step - loss: 176.6469 - mean_absolute_error: 11.3578\n",
            "313/313 [==============================] - 6s 18ms/step\n",
            "Epoch 11, Train Loss: 176.64691162109375, Train MAE: 11.357842445373535, Test Loss: 825.6951293945312, Test MAE: 23.88682746887207, MAE for S: 37.18387985229492, MAE for D: 10.589766502380371\n",
            "625/625 [==============================] - 79s 127ms/step - loss: 176.2873 - mean_absolute_error: 11.3525\n",
            "313/313 [==============================] - 8s 25ms/step\n",
            "Epoch 12, Train Loss: 176.28729248046875, Train MAE: 11.352487564086914, Test Loss: 940.84521484375, Test MAE: 25.29477882385254, MAE for S: 40.349056243896484, MAE for D: 10.240488052368164\n",
            "619/625 [============================>.] - ETA: 0s - loss: 178.0298 - mean_absolute_error: 11.3911"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9e992bfb20c3>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Train the model for 70 epochs and capture loss after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.metrics import MeanAbsoluteError\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Separate features and labels\n",
        "X_train_full = train_data[:, :1000]\n",
        "y_train_full = train_data[:, -2:]\n",
        "X_test = test_data[:, :1000]\n",
        "y_test = test_data[:, -2:]\n",
        "\n",
        "# Split training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "X_train_mean = np.mean(X_train, axis=1)\n",
        "X_train_mean = np.reshape(X_train_mean, (-1, 1))\n",
        "X_train_std = np.std(X_train, axis=1)\n",
        "X_train_std = np.reshape(X_train_std, (-1, 1))\n",
        "X_train = (X_train - X_train_mean) / X_train_std\n",
        "\n",
        "X_val_mean = np.mean(X_val, axis=1)\n",
        "X_val_mean = np.reshape(X_val_mean, (-1, 1))\n",
        "X_val_std = np.std(X_val, axis=1)\n",
        "X_val_std = np.reshape(X_val_std, (-1, 1))\n",
        "X_val = (X_val - X_val_mean) / X_val_std\n",
        "\n",
        "X_test_mean = np.mean(X_test, axis=1)\n",
        "X_test_mean = np.reshape(X_test_mean, (-1, 1))\n",
        "X_test_std = np.std(X_test, axis=1)\n",
        "X_test_std = np.reshape(X_test_std, (-1, 1))\n",
        "X_test = (X_test - X_test_mean) / X_test_std\n",
        "\n",
        "# Reshape data for TCN\n",
        "X_train = X_train[:, :, np.newaxis]\n",
        "X_val = X_val[:, :, np.newaxis]\n",
        "X_test = X_test[:, :, np.newaxis]\n",
        "\n",
        "# Build the TCN model\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(X_train.shape[1], 1)),\n",
        "    layers.Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.GlobalMaxPooling1D(),\n",
        "    layers.Dense(50, activation='relu'),\n",
        "    layers.Dense(2)  # Two output nodes, one for S and one for D\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=[MeanAbsoluteError()])\n",
        "\n",
        "for epoch in range(70):\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=40, batch_size=32, validation_data=(X_val, y_val), verbose=1, shuffle=False)\n",
        "    loss = history.history['loss'][0]\n",
        "    mae = history.history['mean_absolute_error'][0]\n",
        "\n",
        "    # Evaluate the model\n",
        "    test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate Mean Absolute Error for S and D separately\n",
        "    mae_s = MeanAbsoluteError()\n",
        "    mae_s.update_state(y_test[:, 0], y_pred[:, 0])\n",
        "    mae_d = MeanAbsoluteError()\n",
        "    mae_d.update_state(y_test[:, 1], y_pred[:, 1])\n",
        "\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {loss}, Train MAE: {mae}, Test Loss: {test_loss}, Test MAE: {test_mae}, MAE for S: {mae_s.result().numpy()}, MAE for D: {mae_d.result().numpy()}\")\n",
        "print(f\"Test MAE: {test_mae}, MAE for S: {mae_s.result().numpy()}, MAE for D: {mae_d.result().numpy()}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jXXWOnptcXyp",
        "outputId": "4ba1a51b-2840-438d-8525-bd40af4140e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "500/500 [==============================] - 62s 121ms/step - loss: 649.0414 - mean_absolute_error: 18.3296 - val_loss: 1629.9437 - val_mean_absolute_error: 36.4111\n",
            "Epoch 2/40\n",
            "500/500 [==============================] - 60s 120ms/step - loss: 221.9544 - mean_absolute_error: 12.5966 - val_loss: 717.0367 - val_mean_absolute_error: 22.5707\n",
            "Epoch 3/40\n",
            "500/500 [==============================] - 60s 121ms/step - loss: 179.1862 - mean_absolute_error: 11.4668 - val_loss: 172.5947 - val_mean_absolute_error: 11.2329\n",
            "Epoch 4/40\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 167.6306 - mean_absolute_error: 11.0062 - val_loss: 161.9399 - val_mean_absolute_error: 10.8544\n",
            "Epoch 5/40\n",
            "500/500 [==============================] - 60s 120ms/step - loss: 164.4415 - mean_absolute_error: 10.8813 - val_loss: 159.2228 - val_mean_absolute_error: 10.7457\n",
            "Epoch 6/40\n",
            "500/500 [==============================] - 61s 121ms/step - loss: 164.0685 - mean_absolute_error: 10.8419 - val_loss: 158.4311 - val_mean_absolute_error: 10.6808\n",
            "Epoch 7/40\n",
            "500/500 [==============================] - 60s 120ms/step - loss: 164.0248 - mean_absolute_error: 10.8448 - val_loss: 167.3729 - val_mean_absolute_error: 10.9113\n",
            "Epoch 8/40\n",
            "500/500 [==============================] - 61s 123ms/step - loss: 164.1026 - mean_absolute_error: 10.8496 - val_loss: 157.2756 - val_mean_absolute_error: 10.6526\n",
            "Epoch 9/40\n",
            "500/500 [==============================] - 60s 120ms/step - loss: 171.1188 - mean_absolute_error: 11.1354 - val_loss: 194.0795 - val_mean_absolute_error: 11.6593\n",
            "Epoch 10/40\n",
            "500/500 [==============================] - 60s 120ms/step - loss: 176.4152 - mean_absolute_error: 11.3535 - val_loss: 173.9643 - val_mean_absolute_error: 11.2203\n",
            "Epoch 11/40\n",
            "500/500 [==============================] - 60s 120ms/step - loss: 178.3469 - mean_absolute_error: 11.4311 - val_loss: 201.4432 - val_mean_absolute_error: 11.8141\n",
            "Epoch 12/40\n",
            "500/500 [==============================] - 61s 123ms/step - loss: 178.2564 - mean_absolute_error: 11.4244 - val_loss: 171.4788 - val_mean_absolute_error: 11.1604\n",
            "Epoch 13/40\n",
            "500/500 [==============================] - 60s 121ms/step - loss: 178.1868 - mean_absolute_error: 11.4252 - val_loss: 173.8043 - val_mean_absolute_error: 11.2034\n",
            "Epoch 14/40\n",
            "500/500 [==============================] - 60s 120ms/step - loss: 177.9980 - mean_absolute_error: 11.4164 - val_loss: 178.2190 - val_mean_absolute_error: 11.3061\n",
            "Epoch 15/40\n",
            "500/500 [==============================] - 63s 125ms/step - loss: 177.8768 - mean_absolute_error: 11.4133 - val_loss: 173.9363 - val_mean_absolute_error: 11.2096\n",
            "Epoch 16/40\n",
            "500/500 [==============================] - 60s 121ms/step - loss: 177.7797 - mean_absolute_error: 11.4111 - val_loss: 179.3263 - val_mean_absolute_error: 11.3326\n",
            "Epoch 17/40\n",
            "286/500 [================>.............] - ETA: 25s - loss: 177.6597 - mean_absolute_error: 11.4033"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-8e51bae109d2>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1689\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1692\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   \u001b[0mflat_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m   \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    911\u001b[0m                           expand_composites=expand_composites)\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m   \u001b[0mflat_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m   \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0mexpand_composites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Error is not decreasign in TCN model, i stop epochs with keyboard interrupt"
      ],
      "metadata": {
        "id": "EkhZyAOgbJGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Absolute Error for S and D separately\n",
        "mae_s = MeanAbsoluteError()\n",
        "mae_s.update_state(y_test[:, 0], y_pred[:, 0])\n",
        "mae_d = MeanAbsoluteError()\n",
        "mae_d.update_state(y_test[:, 1], y_pred[:, 1])\n",
        "\n",
        "\n",
        "print(f\"Epoch {epoch+1}, Train Loss: {loss}, Train MAE: {mae}, Test Loss: {test_loss}, Test MAE: {test_mae}, MAE for S: {mae_s.result().numpy()}, MAE for D: {mae_d.result().numpy()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPAxyToeiai2",
        "outputId": "0b8cbde3-94b9-4816-dc57-c18bc5516db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 8s 24ms/step\n",
            "Epoch 1, Train Loss: 176.28729248046875, Train MAE: 11.352487564086914, Test Loss: 709.376220703125, Test MAE: 22.24258041381836, MAE for S: 33.9527702331543, MAE for D: 10.532404899597168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- After running TCN model 33 MAE is acheived for systolic and 10 MAE is acheived foe diastolic"
      ],
      "metadata": {
        "id": "-Ap5L14SY25X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FCN_Plus Model\n",
        "- For both systolic and diastolic BP"
      ],
      "metadata": {
        "id": "8FyzeV4ekEPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.metrics import MeanAbsoluteError\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Separate features and labels\n",
        "X_train_full = train_data[:, :1000]\n",
        "y_train_full = train_data[:, -2:]\n",
        "X_test = test_data[:, :1000]\n",
        "y_test = test_data[:, -2:]\n",
        "\n",
        "# Split training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.3, random_state=42, shuffle=True)\n",
        "\n",
        "# Scale the features\n",
        "X_train_mean = np.mean(X_train, axis=1)\n",
        "X_train_mean = np.reshape(X_train_mean, (-1, 1))\n",
        "X_train_std = np.std(X_train, axis=1)\n",
        "X_train_std = np.reshape(X_train_std, (-1, 1))\n",
        "X_train = (X_train - X_train_mean) / X_train_std\n",
        "\n",
        "X_val_mean = np.mean(X_val, axis=1)\n",
        "X_val_mean = np.reshape(X_val_mean, (-1, 1))\n",
        "X_val_std = np.std(X_val, axis=1)\n",
        "X_val_std = np.reshape(X_val_std, (-1, 1))\n",
        "X_val = (X_val - X_val_mean) / X_val_std\n",
        "\n",
        "X_test_mean = np.mean(X_test, axis=1)\n",
        "X_test_mean = np.reshape(X_test_mean, (-1, 1))\n",
        "X_test_std = np.std(X_test, axis=1)\n",
        "X_test_std = np.reshape(X_test_std, (-1, 1))\n",
        "X_test = (X_test - X_test_mean) / X_test_std\n",
        "\n",
        "# Reshape data for FCN_PLUS\n",
        "X_train = X_train[:, :, np.newaxis]\n",
        "X_val = X_val[:, :, np.newaxis]\n",
        "X_test = X_test[:, :, np.newaxis]\n",
        "\n",
        "# Build the FCN_PLUS model\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(X_train.shape[1], 1)),\n",
        "    layers.Conv1D(filters=128, kernel_size=8, padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Conv1D(filters=256, kernel_size=5, padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Conv1D(filters=128, kernel_size=3, padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.GlobalAveragePooling1D(),\n",
        "    layers.Dense(2)  # Two output nodes for S and D\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=[MeanAbsoluteError()])\n",
        "\n",
        "# Train the model for 70 epochs and capture loss after each epoch\n",
        "for epoch in range(40):\n",
        "    history = model.fit(X_train, y_train, epochs=1, batch_size=32, validation_data=(X_val, y_val), shuffle=True, verbose=1)\n",
        "\n",
        "    train_loss = history.history['loss'][0]\n",
        "    train_mae = history.history['mean_absolute_error'][0]\n",
        "\n",
        "    val_loss = history.history['val_loss'][0]\n",
        "    val_mae = history.history['val_mean_absolute_error'][0]\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate Mean Absolute Error for S and D separately\n",
        "    mae_s = MeanAbsoluteError()\n",
        "    mae_s.update_state(y_test[:, 0], y_pred[:, 0])\n",
        "    mae_d = MeanAbsoluteError()\n",
        "    mae_d.update_state(y_test[:, 1], y_pred[:, 1])\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}, Train MAE: {train_mae}, Val Loss: {val_loss}, Val MAE: {val_mae}, Test Loss: {test_loss}, Test MAE: {test_mae}, MAE for S: {mae_s.result().numpy()}, MAE for D: {mae_d.result().numpy()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "id": "0AXEAmFMj74K",
        "outputId": "5300008a-24ac-4751-e9b2-804698bb8a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "438/438 [==============================] - 28s 37ms/step - loss: 5982.3755 - mean_absolute_error: 72.5120 - val_loss: 1938.5471 - val_mean_absolute_error: 39.8225\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Epoch 1, Train Loss: 5982.37548828125, Train MAE: 72.51203918457031, Val Loss: 1938.547119140625, Val MAE: 39.82249450683594, Test Loss: 4860.16845703125, Test MAE: 58.725738525390625, MAE for S: 94.5342025756836, MAE for D: 22.917261123657227\n",
            "438/438 [==============================] - 15s 34ms/step - loss: 500.7754 - mean_absolute_error: 17.1513 - val_loss: 330.5477 - val_mean_absolute_error: 15.1395\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Epoch 2, Train Loss: 500.7753601074219, Train MAE: 17.151260375976562, Val Loss: 330.54766845703125, Val MAE: 15.13948917388916, Test Loss: 1236.1234130859375, Test MAE: 28.3886775970459, MAE for S: 47.78641891479492, MAE for D: 8.99095344543457\n",
            "438/438 [==============================] - 15s 34ms/step - loss: 104.3839 - mean_absolute_error: 8.5168 - val_loss: 183.0523 - val_mean_absolute_error: 11.0927\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Epoch 3, Train Loss: 104.38391876220703, Train MAE: 8.516800880432129, Val Loss: 183.05227661132812, Val MAE: 11.09272289276123, Test Loss: 609.268310546875, Test MAE: 20.736804962158203, MAE for S: 31.830087661743164, MAE for D: 9.64352035522461\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 88.7319 - mean_absolute_error: 7.7259 - val_loss: 94.4088 - val_mean_absolute_error: 7.8066\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Epoch 4, Train Loss: 88.73191833496094, Train MAE: 7.725855827331543, Val Loss: 94.40876770019531, Val MAE: 7.806575298309326, Test Loss: 331.9380798339844, Test MAE: 16.27479362487793, MAE for S: 18.815088272094727, MAE for D: 13.734506607055664\n",
            "438/438 [==============================] - 15s 34ms/step - loss: 79.0792 - mean_absolute_error: 7.2356 - val_loss: 230.9330 - val_mean_absolute_error: 12.9192\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Epoch 5, Train Loss: 79.07915496826172, Train MAE: 7.235583305358887, Val Loss: 230.93299865722656, Val MAE: 12.919173240661621, Test Loss: 533.8574829101562, Test MAE: 19.53746795654297, MAE for S: 29.8619441986084, MAE for D: 9.21298599243164\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 70.9330 - mean_absolute_error: 6.8457 - val_loss: 1127.2970 - val_mean_absolute_error: 31.4213\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Epoch 6, Train Loss: 70.93303680419922, Train MAE: 6.8456645011901855, Val Loss: 1127.2969970703125, Val MAE: 31.42133140563965, Test Loss: 1206.983642578125, Test MAE: 33.07942199707031, MAE for S: 25.558225631713867, MAE for D: 40.60060119628906\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 63.3132 - mean_absolute_error: 6.4665 - val_loss: 405.7746 - val_mean_absolute_error: 17.4041\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Epoch 7, Train Loss: 63.31321334838867, Train MAE: 6.4665422439575195, Val Loss: 405.77459716796875, Val MAE: 17.404056549072266, Test Loss: 416.1069030761719, Test MAE: 18.042444229125977, MAE for S: 11.68154239654541, MAE for D: 24.40334701538086\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 54.3970 - mean_absolute_error: 5.9731 - val_loss: 90.1273 - val_mean_absolute_error: 7.5977\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Epoch 8, Train Loss: 54.39699172973633, Train MAE: 5.973065376281738, Val Loss: 90.12730407714844, Val MAE: 7.597677707672119, Test Loss: 216.97012329101562, Test MAE: 12.412364959716797, MAE for S: 7.564882755279541, MAE for D: 17.259838104248047\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 45.1603 - mean_absolute_error: 5.4048 - val_loss: 387.1973 - val_mean_absolute_error: 17.4753\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Epoch 9, Train Loss: 45.160343170166016, Train MAE: 5.40478515625, Val Loss: 387.19732666015625, Val MAE: 17.47528839111328, Test Loss: 390.8694763183594, Test MAE: 17.63211441040039, MAE for S: 10.862360954284668, MAE for D: 24.40185546875\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 38.5164 - mean_absolute_error: 4.9500 - val_loss: 382.6238 - val_mean_absolute_error: 15.4952\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Epoch 10, Train Loss: 38.51643371582031, Train MAE: 4.94995641708374, Val Loss: 382.623779296875, Val MAE: 15.495237350463867, Test Loss: 256.0328369140625, Test MAE: 14.725652694702148, MAE for S: 14.09363079071045, MAE for D: 15.35766887664795\n",
            "141/438 [========>.....................] - ETA: 9s - loss: 32.6751 - mean_absolute_error: 4.5310"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-14f286e8730e>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Train the model for 70 epochs and capture loss after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1689\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1692\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \"\"\"\n\u001b[1;32m   1159\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 14 and 15 MAE is acheived after 10 epochs"
      ],
      "metadata": {
        "id": "JcpP1RtFbqm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.metrics import MeanAbsoluteError\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separate features and labels\n",
        "X_train_full = train_data[:, :1000]\n",
        "y_train_full = train_data[:, -2]  # Only Systolic Blood Pressure\n",
        "X_test = test_data[:, :1000]\n",
        "y_test = test_data[:, -2]  # Only Systolic Blood Pressure\n",
        "\n",
        "# Split training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.3, random_state=42, shuffle=True)\n",
        "\n",
        "# Scale the features\n",
        "X_train_mean = np.mean(X_train, axis=1)\n",
        "X_train_mean = np.reshape(X_train_mean, (-1, 1))\n",
        "X_train_std = np.std(X_train, axis=1)\n",
        "X_train_std = np.reshape(X_train_std, (-1, 1))\n",
        "X_train = (X_train - X_train_mean) / X_train_std\n",
        "\n",
        "X_val_mean = np.mean(X_val, axis=1)\n",
        "X_val_mean = np.reshape(X_val_mean, (-1, 1))\n",
        "X_val_std = np.std(X_val, axis=1)\n",
        "X_val_std = np.reshape(X_val_std, (-1, 1))\n",
        "X_val = (X_val - X_val_mean) / X_val_std\n",
        "\n",
        "X_test_mean = np.mean(X_test, axis=1)\n",
        "X_test_mean = np.reshape(X_test_mean, (-1, 1))\n",
        "X_test_std = np.std(X_test, axis=1)\n",
        "X_test_std = np.reshape(X_test_std, (-1, 1))\n",
        "X_test = (X_test - X_test_mean) / X_test_std\n",
        "\n",
        "# Reshape data for FCN_PLUS\n",
        "X_train = X_train[:, :, np.newaxis]\n",
        "X_val = X_val[:, :, np.newaxis]\n",
        "X_test = X_test[:, :, np.newaxis]\n",
        "\n",
        "# Build the FCN_PLUS model\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(X_train.shape[1], 1)),\n",
        "    layers.Conv1D(filters=128, kernel_size=8, padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Conv1D(filters=256, kernel_size=5, padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Conv1D(filters=128, kernel_size=3, padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.GlobalAveragePooling1D(),\n",
        "    layers.Dense(1)  # Single output node for Systolic Blood Pressure\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=[MeanAbsoluteError()])\n",
        "\n",
        "# Train the model for 70 epochs and capture loss after each epoch\n",
        "for epoch in range(50):\n",
        "    history = model.fit(X_train, y_train, epochs=1, batch_size=32, validation_data=(X_val, y_val), shuffle=False, verbose=1)\n",
        "\n",
        "    train_loss = history.history['loss'][0]\n",
        "    train_mae = history.history['mean_absolute_error'][0]\n",
        "\n",
        "    val_loss = history.history['val_loss'][0]\n",
        "    val_mae = history.history['val_mean_absolute_error'][0]\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}, Train MAE: {train_mae}, Val Loss: {val_loss}, Val MAE: {val_mae}, Test Loss: {test_loss}, Test MAE: {test_mae}\")\n",
        "    prediction = model.predict(X_test)\n",
        "    mae_systolic = MeanAbsoluteError()\n",
        "    mae_systolic.update_state(y_test, prediction)\n",
        "    print(\"Mean absolute error for systolic is: \",mae_systolic)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "nJuzTfjkmO56",
        "outputId": "3de6dfda-91da-444e-d946-737aa45fa8a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "438/438 [==============================] - 18s 35ms/step - loss: 9461.7539 - mean_absolute_error: 94.9920 - val_loss: 4303.3408 - val_mean_absolute_error: 64.0743\n",
            "Epoch 1, Train Loss: 9461.75390625, Train MAE: 94.99202728271484, Val Loss: 4303.3408203125, Val MAE: 64.0743408203125, Test Loss: 11595.1640625, Test MAE: 107.09507751464844\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 1319.6981 - mean_absolute_error: 30.1590 - val_loss: 623.8156 - val_mean_absolute_error: 21.5216\n",
            "Epoch 2, Train Loss: 1319.6981201171875, Train MAE: 30.158967971801758, Val Loss: 623.8156127929688, Val MAE: 21.521615982055664, Test Loss: 295.0278015136719, Test MAE: 14.062084197998047\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 100.1823 - mean_absolute_error: 8.2912 - val_loss: 122.0509 - val_mean_absolute_error: 9.1391\n",
            "Epoch 3, Train Loss: 100.18232727050781, Train MAE: 8.291244506835938, Val Loss: 122.05088806152344, Val MAE: 9.139059066772461, Test Loss: 895.0820922851562, Test MAE: 28.633516311645508\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 52.0269 - mean_absolute_error: 5.7884 - val_loss: 250.6754 - val_mean_absolute_error: 14.4266\n",
            "Epoch 4, Train Loss: 52.02686309814453, Train MAE: 5.788358211517334, Val Loss: 250.6753692626953, Val MAE: 14.426644325256348, Test Loss: 56.08665084838867, Test MAE: 5.95918607711792\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 42.8723 - mean_absolute_error: 5.2011 - val_loss: 356.3204 - val_mean_absolute_error: 18.0491\n",
            "Epoch 5, Train Loss: 42.87226486206055, Train MAE: 5.2010602951049805, Val Loss: 356.3204040527344, Val MAE: 18.049074172973633, Test Loss: 97.9220962524414, Test MAE: 8.64022445678711\n",
            "179/438 [===========>..................] - ETA: 7s - loss: 40.0032 - mean_absolute_error: 5.0098Epoch 7, Train Loss: 34.593753814697266, Train MAE: 4.6430840492248535, Val Loss: 555.0579833984375, Val MAE: 22.76662254333496, Test Loss: 212.87857055664062, Test MAE: 12.852821350097656\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 31.1741 - mean_absolute_error: 4.3917 - val_loss: 26.5567 - val_mean_absolute_error: 4.1417\n",
            "Epoch 8, Train Loss: 31.174095153808594, Train MAE: 4.391713619232178, Val Loss: 26.556678771972656, Val MAE: 4.141658306121826, Test Loss: 123.22640228271484, Test MAE: 9.340079307556152\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 30.0049 - mean_absolute_error: 4.2843 - val_loss: 52.7196 - val_mean_absolute_error: 6.0569\n",
            "Epoch 9, Train Loss: 30.004863739013672, Train MAE: 4.284315586090088, Val Loss: 52.719581604003906, Val MAE: 6.056946754455566, Test Loss: 214.00787353515625, Test MAE: 13.22772216796875\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 28.6581 - mean_absolute_error: 4.1626 - val_loss: 341.6177 - val_mean_absolute_error: 17.8122\n",
            "Epoch 10, Train Loss: 28.65806007385254, Train MAE: 4.162642002105713, Val Loss: 341.61767578125, Val MAE: 17.812162399291992, Test Loss: 217.87034606933594, Test MAE: 13.576499938964844\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 27.1003 - mean_absolute_error: 4.0349 - val_loss: 186.5325 - val_mean_absolute_error: 13.0953\n",
            "Epoch 11, Train Loss: 27.10032844543457, Train MAE: 4.0348687171936035, Val Loss: 186.53248596191406, Val MAE: 13.095267295837402, Test Loss: 105.5135498046875, Test MAE: 9.121378898620605\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 23.7431 - mean_absolute_error: 3.7334 - val_loss: 1168.1189 - val_mean_absolute_error: 33.8055\n",
            "Epoch 12, Train Loss: 23.74306297302246, Train MAE: 3.7333920001983643, Val Loss: 1168.118896484375, Val MAE: 33.80548095703125, Test Loss: 993.056884765625, Test MAE: 30.719669342041016\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 22.7756 - mean_absolute_error: 3.6393 - val_loss: 2439.0288 - val_mean_absolute_error: 47.4673\n",
            "Epoch 13, Train Loss: 22.775585174560547, Train MAE: 3.6393091678619385, Val Loss: 2439.02880859375, Val MAE: 47.4672966003418, Test Loss: 1774.8111572265625, Test MAE: 39.522422790527344\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 23.2162 - mean_absolute_error: 3.6798 - val_loss: 41.1549 - val_mean_absolute_error: 5.2221\n",
            "Epoch 14, Train Loss: 23.21616554260254, Train MAE: 3.6797659397125244, Val Loss: 41.15491485595703, Val MAE: 5.22205924987793, Test Loss: 86.4804916381836, Test MAE: 7.719764232635498\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 19.6529 - mean_absolute_error: 3.3809 - val_loss: 162.1011 - val_mean_absolute_error: 12.1074\n",
            "Epoch 15, Train Loss: 19.652910232543945, Train MAE: 3.380937337875366, Val Loss: 162.1011199951172, Val MAE: 12.107429504394531, Test Loss: 278.295654296875, Test MAE: 15.705945014953613\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 20.4595 - mean_absolute_error: 3.4412 - val_loss: 61.0152 - val_mean_absolute_error: 6.8471\n",
            "Epoch 16, Train Loss: 20.459518432617188, Train MAE: 3.441210985183716, Val Loss: 61.01522445678711, Val MAE: 6.847128391265869, Test Loss: 109.9422378540039, Test MAE: 8.90754222869873\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 19.4884 - mean_absolute_error: 3.3532 - val_loss: 79.6563 - val_mean_absolute_error: 7.9971\n",
            "Epoch 17, Train Loss: 19.48836898803711, Train MAE: 3.353158950805664, Val Loss: 79.6562728881836, Val MAE: 7.997079849243164, Test Loss: 131.3017578125, Test MAE: 9.637834548950195\n",
            "291/438 [==================>...........] - ETA: 4s - loss: 20.3972 - mean_absolute_error: 3.4461"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9c11e8f04513>\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Train the model for 70 epochs and capture loss after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1689\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1692\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mio_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_break\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import mean_absolute_error\n",
        "prediction = model.predict(X_test)\n",
        "\n",
        "mae_systolic = MeanAbsoluteError()\n",
        "mae_systolic.update_state(y_test, prediction)\n",
        "print(\"Mean absolute error is: \",mae_systolic)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKZ0kLYSplCQ",
        "outputId": "b1212cfb-5cc8-4c4b-bee2-41ae4f4419cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18RXqIg7uWEZ",
        "outputId": "ed0157fc-75d9-453a-aa34-21983b7d74d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.metrics.regression_metrics.MeanAbsoluteError at 0x7a7d5c974fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make predictions and mean absolute error\n",
        "mae_s = MeanAbsoluteError()\n",
        "mae_s.update_state(y_test, prediction)\n",
        "print(\"Mean absolute error is: \",mae_s.result().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1yqH6CZryO4",
        "outputId": "70a781a4-333a-47cf-d154-8ced13845308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute error is:  4.558425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Good mean absolut error is acheived with FCN algorithm for systolic BP"
      ],
      "metadata": {
        "id": "hUD-bMUcpB6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FCN_Plus Model\n",
        "- For Systolic Blood Pressure"
      ],
      "metadata": {
        "id": "5IT7mtFyJDbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.metrics import MeanAbsoluteError\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separate features and labels\n",
        "X_train_full = train_data[:, :1000]\n",
        "y_train_full = train_data[:, -2]  # Only Systolic Blood Pressure\n",
        "X_test = test_data[:, :1000]\n",
        "y_test = test_data[:, -2]  # Only Systolic Blood Pressure\n",
        "\n",
        "# Split training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.3, random_state=42, shuffle=True)\n",
        "\n",
        "# Scale the features\n",
        "X_train_mean = np.mean(X_train, axis=1)\n",
        "X_train_mean = np.reshape(X_train_mean, (-1, 1))\n",
        "X_train_std = np.std(X_train, axis=1)\n",
        "X_train_std = np.reshape(X_train_std, (-1, 1))\n",
        "X_train = (X_train - X_train_mean) / X_train_std\n",
        "\n",
        "X_val_mean = np.mean(X_val, axis=1)\n",
        "X_val_mean = np.reshape(X_val_mean, (-1, 1))\n",
        "X_val_std = np.std(X_val, axis=1)\n",
        "X_val_std = np.reshape(X_val_std, (-1, 1))\n",
        "X_val = (X_val - X_val_mean) / X_val_std\n",
        "\n",
        "X_test_mean = np.mean(X_test, axis=1)\n",
        "X_test_mean = np.reshape(X_test_mean, (-1, 1))\n",
        "X_test_std = np.std(X_test, axis=1)\n",
        "X_test_std = np.reshape(X_test_std, (-1, 1))\n",
        "X_test = (X_test - X_test_mean) / X_test_std\n",
        "\n",
        "# Reshape data for FCN_PLUS\n",
        "X_train = X_train[:, :, np.newaxis]\n",
        "X_val = X_val[:, :, np.newaxis]\n",
        "X_test = X_test[:, :, np.newaxis]\n",
        "\n",
        "# Build the FCN_PLUS model\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(X_train.shape[1], 1)),\n",
        "    layers.Conv1D(filters=128, kernel_size=8, padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Conv1D(filters=256, kernel_size=5, padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Conv1D(filters=128, kernel_size=3, padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.GlobalAveragePooling1D(),\n",
        "    layers.Dense(1)  # Single output node for Systolic Blood Pressure\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=[MeanAbsoluteError()])\n",
        "\n",
        "# Train the model for 70 epochs and capture loss after each epoch\n",
        "for epoch in range(50):\n",
        "    history = model.fit(X_train, y_train, epochs=1, batch_size=32, validation_data=(X_val, y_val), shuffle=False, verbose=1)\n",
        "\n",
        "    train_loss = history.history['loss'][0]\n",
        "    train_mae = history.history['mean_absolute_error'][0]\n",
        "\n",
        "    val_loss = history.history['val_loss'][0]\n",
        "    val_mae = history.history['val_mean_absolute_error'][0]\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}, Train MAE: {train_mae}, Val Loss: {val_loss}, Val MAE: {val_mae}, Test Loss: {test_loss}, Test MAE: {test_mae}\")\n",
        "    prediction = model.predict(X_test)\n",
        "    mae_systolic = MeanAbsoluteError()\n",
        "    mae_systolic.update_state(y_test, prediction)\n",
        "    print(\"Mean absolute error for systolic is: \",mae_systolic.result().numpy())\n",
        "# mae = mean_absolute_error(prediction,y_test)\n",
        "# mae1 = np.mean(np.abs(y_test - prediction))\n",
        "# print(f\"Mean absolute error for systolic BP is: \", mae1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjOrrMbtwJB4",
        "outputId": "1bbc7f4c-1cf8-4a03-8098-685d59b097a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "438/438 [==============================] - 19s 34ms/step - loss: 8521.0732 - mean_absolute_error: 89.4834 - val_loss: 2967.2517 - val_mean_absolute_error: 52.5870\n",
            "Epoch 1, Train Loss: 8521.0732421875, Train MAE: 89.48343658447266, Val Loss: 2967.251708984375, Val MAE: 52.58696365356445, Test Loss: 9428.267578125, Test MAE: 96.44403076171875\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 901.7488 - mean_absolute_error: 24.2288 - val_loss: 221.2187 - val_mean_absolute_error: 12.2571\n",
            "Epoch 2, Train Loss: 901.748779296875, Train MAE: 24.22879409790039, Val Loss: 221.2186737060547, Val MAE: 12.257135391235352, Test Loss: 1870.2581787109375, Test MAE: 42.220458984375\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 90.5646 - mean_absolute_error: 7.8541 - val_loss: 664.3434 - val_mean_absolute_error: 24.3570\n",
            "Epoch 3, Train Loss: 90.56460571289062, Train MAE: 7.854118347167969, Val Loss: 664.3434448242188, Val MAE: 24.35699462890625, Test Loss: 2095.77783203125, Test MAE: 45.20207214355469\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 48.2793 - mean_absolute_error: 5.5093 - val_loss: 155.3186 - val_mean_absolute_error: 10.8479\n",
            "Epoch 4, Train Loss: 48.27926254272461, Train MAE: 5.509310722351074, Val Loss: 155.31857299804688, Val MAE: 10.847882270812988, Test Loss: 505.0543518066406, Test MAE: 21.235960006713867\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 41.2211 - mean_absolute_error: 5.0645 - val_loss: 82.9247 - val_mean_absolute_error: 7.6369\n",
            "Epoch 5, Train Loss: 41.221092224121094, Train MAE: 5.064549446105957, Val Loss: 82.9246597290039, Val MAE: 7.636858940124512, Test Loss: 288.46771240234375, Test MAE: 15.522164344787598\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 37.7927 - mean_absolute_error: 4.8382 - val_loss: 252.0116 - val_mean_absolute_error: 14.5607\n",
            "Epoch 6, Train Loss: 37.7927131652832, Train MAE: 4.838212013244629, Val Loss: 252.0115966796875, Val MAE: 14.560725212097168, Test Loss: 580.5701293945312, Test MAE: 23.05978012084961\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 35.6565 - mean_absolute_error: 4.6907 - val_loss: 219.5559 - val_mean_absolute_error: 13.6026\n",
            "Epoch 7, Train Loss: 35.656463623046875, Train MAE: 4.690738201141357, Val Loss: 219.55593872070312, Val MAE: 13.602575302124023, Test Loss: 507.9708557128906, Test MAE: 21.645381927490234\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 33.2623 - mean_absolute_error: 4.5251 - val_loss: 75.0627 - val_mean_absolute_error: 7.3432\n",
            "Epoch 8, Train Loss: 33.26227951049805, Train MAE: 4.525101184844971, Val Loss: 75.06266021728516, Val MAE: 7.343235492706299, Test Loss: 233.57347106933594, Test MAE: 13.932061195373535\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 31.3216 - mean_absolute_error: 4.3766 - val_loss: 283.9063 - val_mean_absolute_error: 15.8027\n",
            "Epoch 9, Train Loss: 31.32161521911621, Train MAE: 4.376617908477783, Val Loss: 283.9063415527344, Val MAE: 15.802735328674316, Test Loss: 545.8175659179688, Test MAE: 22.536569595336914\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 29.4184 - mean_absolute_error: 4.2238 - val_loss: 284.9803 - val_mean_absolute_error: 15.9640\n",
            "Epoch 10, Train Loss: 29.418397903442383, Train MAE: 4.22376012802124, Val Loss: 284.9803466796875, Val MAE: 15.963973045349121, Test Loss: 516.6219482421875, Test MAE: 21.84578514099121\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 27.3635 - mean_absolute_error: 4.0526 - val_loss: 213.4670 - val_mean_absolute_error: 13.7073\n",
            "Epoch 11, Train Loss: 27.363483428955078, Train MAE: 4.052563190460205, Val Loss: 213.46697998046875, Val MAE: 13.707315444946289, Test Loss: 381.4630432128906, Test MAE: 18.532684326171875\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 25.7171 - mean_absolute_error: 3.9064 - val_loss: 294.9147 - val_mean_absolute_error: 16.4476\n",
            "Epoch 12, Train Loss: 25.71713638305664, Train MAE: 3.9064383506774902, Val Loss: 294.9147033691406, Val MAE: 16.447601318359375, Test Loss: 466.7426452636719, Test MAE: 20.728601455688477\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 24.0453 - mean_absolute_error: 3.7605 - val_loss: 42.3411 - val_mean_absolute_error: 5.3109\n",
            "Epoch 13, Train Loss: 24.045305252075195, Train MAE: 3.760479688644409, Val Loss: 42.3410530090332, Val MAE: 5.310909271240234, Test Loss: 38.60336685180664, Test MAE: 4.821203708648682\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 22.9439 - mean_absolute_error: 3.6612 - val_loss: 30.6824 - val_mean_absolute_error: 4.4003\n",
            "Epoch 14, Train Loss: 22.94388771057129, Train MAE: 3.661193609237671, Val Loss: 30.682395935058594, Val MAE: 4.400301933288574, Test Loss: 35.86738967895508, Test MAE: 4.4376373291015625\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 21.6677 - mean_absolute_error: 3.5465 - val_loss: 279.0797 - val_mean_absolute_error: 15.9946\n",
            "Epoch 15, Train Loss: 21.667734146118164, Train MAE: 3.546489953994751, Val Loss: 279.07965087890625, Val MAE: 15.994560241699219, Test Loss: 168.62939453125, Test MAE: 11.858495712280273\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 20.8709 - mean_absolute_error: 3.4784 - val_loss: 43.3300 - val_mean_absolute_error: 5.5968\n",
            "Epoch 16, Train Loss: 20.87094497680664, Train MAE: 3.4784200191497803, Val Loss: 43.32997512817383, Val MAE: 5.5968146324157715, Test Loss: 93.41024780273438, Test MAE: 7.8958282470703125\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 20.1045 - mean_absolute_error: 3.4063 - val_loss: 72.1033 - val_mean_absolute_error: 7.3122\n",
            "Epoch 17, Train Loss: 20.10445785522461, Train MAE: 3.406301736831665, Val Loss: 72.10334014892578, Val MAE: 7.312188625335693, Test Loss: 56.65426254272461, Test MAE: 6.1758270263671875\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 19.3183 - mean_absolute_error: 3.3365 - val_loss: 210.7187 - val_mean_absolute_error: 13.8817\n",
            "Epoch 18, Train Loss: 19.31829071044922, Train MAE: 3.3365421295166016, Val Loss: 210.7187042236328, Val MAE: 13.881689071655273, Test Loss: 263.9093017578125, Test MAE: 15.126412391662598\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 18.7027 - mean_absolute_error: 3.2862 - val_loss: 107.0120 - val_mean_absolute_error: 9.6716\n",
            "Epoch 19, Train Loss: 18.70269775390625, Train MAE: 3.286163568496704, Val Loss: 107.01200866699219, Val MAE: 9.671648979187012, Test Loss: 138.78651428222656, Test MAE: 10.39538860321045\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 18.1284 - mean_absolute_error: 3.2392 - val_loss: 20.3507 - val_mean_absolute_error: 3.5629\n",
            "Epoch 20, Train Loss: 18.128433227539062, Train MAE: 3.2391774654388428, Val Loss: 20.3507137298584, Val MAE: 3.562877893447876, Test Loss: 39.48347473144531, Test MAE: 4.59555196762085\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 17.4977 - mean_absolute_error: 3.1888 - val_loss: 41.4434 - val_mean_absolute_error: 5.3847\n",
            "Epoch 21, Train Loss: 17.497682571411133, Train MAE: 3.1887669563293457, Val Loss: 41.443382263183594, Val MAE: 5.38466215133667, Test Loss: 65.23228454589844, Test MAE: 6.290860176086426\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 17.1904 - mean_absolute_error: 3.1636 - val_loss: 192.1850 - val_mean_absolute_error: 13.1449\n",
            "Epoch 22, Train Loss: 17.19036102294922, Train MAE: 3.163625478744507, Val Loss: 192.18502807617188, Val MAE: 13.14493465423584, Test Loss: 224.41677856445312, Test MAE: 13.688102722167969\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 16.8828 - mean_absolute_error: 3.1341 - val_loss: 352.2828 - val_mean_absolute_error: 18.0131\n",
            "Epoch 23, Train Loss: 16.88280487060547, Train MAE: 3.134089946746826, Val Loss: 352.2828063964844, Val MAE: 18.013145446777344, Test Loss: 340.41326904296875, Test MAE: 17.37327766418457\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 16.3926 - mean_absolute_error: 3.0921 - val_loss: 49.2793 - val_mean_absolute_error: 6.0747\n",
            "Epoch 24, Train Loss: 16.39261245727539, Train MAE: 3.0921316146850586, Val Loss: 49.27932357788086, Val MAE: 6.07465124130249, Test Loss: 70.0379867553711, Test MAE: 6.655644416809082\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 16.0335 - mean_absolute_error: 3.0632 - val_loss: 63.2458 - val_mean_absolute_error: 7.0007\n",
            "Epoch 25, Train Loss: 16.033470153808594, Train MAE: 3.0632083415985107, Val Loss: 63.245750427246094, Val MAE: 7.000720024108887, Test Loss: 81.43824768066406, Test MAE: 7.2842631340026855\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 15.8904 - mean_absolute_error: 3.0516 - val_loss: 112.5528 - val_mean_absolute_error: 9.8107\n",
            "Epoch 26, Train Loss: 15.890351295471191, Train MAE: 3.051590919494629, Val Loss: 112.55279541015625, Val MAE: 9.810687065124512, Test Loss: 135.3609619140625, Test MAE: 10.138972282409668\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 17s 39ms/step - loss: 15.4024 - mean_absolute_error: 3.0093 - val_loss: 62.0997 - val_mean_absolute_error: 6.7224\n",
            "Epoch 27, Train Loss: 15.402363777160645, Train MAE: 3.0093424320220947, Val Loss: 62.09967803955078, Val MAE: 6.722404956817627, Test Loss: 84.03135681152344, Test MAE: 7.363379001617432\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 15.2767 - mean_absolute_error: 3.0009 - val_loss: 28.6598 - val_mean_absolute_error: 4.4498\n",
            "Epoch 28, Train Loss: 15.276732444763184, Train MAE: 3.000885486602783, Val Loss: 28.659814834594727, Val MAE: 4.449817657470703, Test Loss: 47.004756927490234, Test MAE: 5.1660237312316895\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 14.8884 - mean_absolute_error: 2.9658 - val_loss: 100.3243 - val_mean_absolute_error: 9.1158\n",
            "Epoch 29, Train Loss: 14.888409614562988, Train MAE: 2.9657859802246094, Val Loss: 100.32427215576172, Val MAE: 9.11584758758545, Test Loss: 116.96965026855469, Test MAE: 9.186388969421387\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 14.6849 - mean_absolute_error: 2.9483 - val_loss: 13.2046 - val_mean_absolute_error: 2.8907\n",
            "Epoch 30, Train Loss: 14.684897422790527, Train MAE: 2.9482932090759277, Val Loss: 13.20458698272705, Val MAE: 2.890716791152954, Test Loss: 41.16861343383789, Test MAE: 5.122066974639893\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 14.5053 - mean_absolute_error: 2.9317 - val_loss: 219.7394 - val_mean_absolute_error: 14.2896\n",
            "Epoch 31, Train Loss: 14.50527572631836, Train MAE: 2.9316506385803223, Val Loss: 219.73941040039062, Val MAE: 14.289644241333008, Test Loss: 237.47940063476562, Test MAE: 14.237815856933594\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 14.2303 - mean_absolute_error: 2.9078 - val_loss: 78.3071 - val_mean_absolute_error: 8.1434\n",
            "Epoch 32, Train Loss: 14.230255126953125, Train MAE: 2.9078121185302734, Val Loss: 78.30712127685547, Val MAE: 8.143433570861816, Test Loss: 87.80976104736328, Test MAE: 7.670129776000977\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 14.0270 - mean_absolute_error: 2.8896 - val_loss: 16.3992 - val_mean_absolute_error: 3.1321\n",
            "Epoch 33, Train Loss: 14.026968955993652, Train MAE: 2.8895530700683594, Val Loss: 16.3991756439209, Val MAE: 3.132148027420044, Test Loss: 35.85307312011719, Test MAE: 4.463255882263184\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 13.8281 - mean_absolute_error: 2.8716 - val_loss: 15.8737 - val_mean_absolute_error: 3.2312\n",
            "Epoch 34, Train Loss: 13.828118324279785, Train MAE: 2.871607780456543, Val Loss: 15.873656272888184, Val MAE: 3.231182336807251, Test Loss: 43.278499603271484, Test MAE: 5.343381881713867\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 13.5247 - mean_absolute_error: 2.8390 - val_loss: 48.5019 - val_mean_absolute_error: 6.0852\n",
            "Epoch 35, Train Loss: 13.524686813354492, Train MAE: 2.8390445709228516, Val Loss: 48.501853942871094, Val MAE: 6.085162162780762, Test Loss: 59.938167572021484, Test MAE: 6.0482683181762695\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 13.3466 - mean_absolute_error: 2.8268 - val_loss: 22.9703 - val_mean_absolute_error: 3.8734\n",
            "Epoch 36, Train Loss: 13.346575736999512, Train MAE: 2.8268048763275146, Val Loss: 22.970287322998047, Val MAE: 3.873375654220581, Test Loss: 41.06181716918945, Test MAE: 4.762446880340576\n",
            "313/313 [==============================] - 3s 11ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 13.2228 - mean_absolute_error: 2.8145 - val_loss: 13.4219 - val_mean_absolute_error: 2.9092\n",
            "Epoch 37, Train Loss: 13.222833633422852, Train MAE: 2.8144829273223877, Val Loss: 13.421855926513672, Val MAE: 2.9092328548431396, Test Loss: 36.74140167236328, Test MAE: 4.718749046325684\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 12.9172 - mean_absolute_error: 2.7842 - val_loss: 16.4078 - val_mean_absolute_error: 3.1910\n",
            "Epoch 38, Train Loss: 12.91720962524414, Train MAE: 2.784212589263916, Val Loss: 16.40781593322754, Val MAE: 3.191023826599121, Test Loss: 35.48756408691406, Test MAE: 4.425806522369385\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 12.8704 - mean_absolute_error: 2.7803 - val_loss: 9.9050 - val_mean_absolute_error: 2.4278\n",
            "Epoch 39, Train Loss: 12.870410919189453, Train MAE: 2.780250310897827, Val Loss: 9.904962539672852, Val MAE: 2.4278485774993896, Test Loss: 42.38566970825195, Test MAE: 5.265631675720215\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 12.7574 - mean_absolute_error: 2.7712 - val_loss: 16.0359 - val_mean_absolute_error: 3.2683\n",
            "Epoch 40, Train Loss: 12.7574462890625, Train MAE: 2.7711520195007324, Val Loss: 16.035921096801758, Val MAE: 3.268319606781006, Test Loss: 44.13744354248047, Test MAE: 5.413760185241699\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 12.4298 - mean_absolute_error: 2.7370 - val_loss: 12.7164 - val_mean_absolute_error: 2.8868\n",
            "Epoch 41, Train Loss: 12.42979621887207, Train MAE: 2.73695707321167, Val Loss: 12.716375350952148, Val MAE: 2.886760711669922, Test Loss: 45.768951416015625, Test MAE: 5.499139785766602\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 12.3615 - mean_absolute_error: 2.7305 - val_loss: 246.3625 - val_mean_absolute_error: 15.0083\n",
            "Epoch 42, Train Loss: 12.361499786376953, Train MAE: 2.7305281162261963, Val Loss: 246.3625030517578, Val MAE: 15.008328437805176, Test Loss: 272.2906188964844, Test MAE: 15.368354797363281\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 12.2055 - mean_absolute_error: 2.7147 - val_loss: 9.5627 - val_mean_absolute_error: 2.3633\n",
            "Epoch 43, Train Loss: 12.205477714538574, Train MAE: 2.7147057056427, Val Loss: 9.562677383422852, Val MAE: 2.363265037536621, Test Loss: 32.419677734375, Test MAE: 4.334261417388916\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 12.1283 - mean_absolute_error: 2.7100 - val_loss: 317.0882 - val_mean_absolute_error: 17.2347\n",
            "Epoch 44, Train Loss: 12.128321647644043, Train MAE: 2.709973096847534, Val Loss: 317.08819580078125, Val MAE: 17.23473358154297, Test Loss: 376.3393859863281, Test MAE: 18.437297821044922\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 12.0202 - mean_absolute_error: 2.6979 - val_loss: 14.4120 - val_mean_absolute_error: 2.9952\n",
            "Epoch 45, Train Loss: 12.020223617553711, Train MAE: 2.697880744934082, Val Loss: 14.4119873046875, Val MAE: 2.995173215866089, Test Loss: 34.6371955871582, Test MAE: 4.500856876373291\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 11.7805 - mean_absolute_error: 2.6721 - val_loss: 224.8702 - val_mean_absolute_error: 14.4716\n",
            "Epoch 46, Train Loss: 11.780510902404785, Train MAE: 2.672074556350708, Val Loss: 224.8701934814453, Val MAE: 14.471597671508789, Test Loss: 280.0522766113281, Test MAE: 15.778545379638672\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 11.5749 - mean_absolute_error: 2.6501 - val_loss: 24.1925 - val_mean_absolute_error: 4.1138\n",
            "Epoch 47, Train Loss: 11.574935913085938, Train MAE: 2.650116443634033, Val Loss: 24.19249153137207, Val MAE: 4.113831520080566, Test Loss: 36.57700729370117, Test MAE: 4.445120811462402\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 11.4680 - mean_absolute_error: 2.6389 - val_loss: 52.2253 - val_mean_absolute_error: 6.7510\n",
            "Epoch 48, Train Loss: 11.46804428100586, Train MAE: 2.6388964653015137, Val Loss: 52.22533416748047, Val MAE: 6.751041889190674, Test Loss: 91.9526596069336, Test MAE: 8.554784774780273\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 11.2730 - mean_absolute_error: 2.6207 - val_loss: 24.7272 - val_mean_absolute_error: 4.1471\n",
            "Epoch 49, Train Loss: 11.27303695678711, Train MAE: 2.620682716369629, Val Loss: 24.727249145507812, Val MAE: 4.147064685821533, Test Loss: 37.39501953125, Test MAE: 4.530315399169922\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 11.2048 - mean_absolute_error: 2.6133 - val_loss: 108.4205 - val_mean_absolute_error: 9.8379\n",
            "Epoch 50, Train Loss: 11.204849243164062, Train MAE: 2.6132943630218506, Val Loss: 108.42045593261719, Val MAE: 9.837858200073242, Test Loss: 110.39009094238281, Test MAE: 8.913140296936035\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  MeanAbsoluteError(name=mean_absolute_error,dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mean absolute error for systolic is: \",mae_systolic.result().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oQgjUV51v0p",
        "outputId": "442bfd85-365a-445c-f602-44b11aba85df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute error for systolic is:  8.913142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(X_test)\n",
        "mae_systolic = MeanAbsoluteError()\n",
        "mae_systolic.update_state(y_test, prediction)\n",
        "\n",
        "mae_s = MeanAbsoluteError()\n",
        "mae_s.update_state(y_test, prediction)\n",
        "print(\"Mean absolute error is: \",mae_s.result().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZlRAYXR0Dvm",
        "outputId": "92fddd9d-ac98-4b73-d43f-7e06be76fe3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error is:  8.913142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mae_ss = mean_absolute_error(prediction,y_test)\n",
        "mae_ss = np.mean(np.abs(y_test - prediction))\n",
        "print(f\"Mean absolute error for systolic BP is: \", mae_ss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXeFlzAA1efr",
        "outputId": "fcad5991-743d-49dd-b379-e3cd592d46c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute error for systolic BP is:  15.288063152787476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run for 30 more epochs"
      ],
      "metadata": {
        "id": "fpG6y_sT249l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue training for 30 more epochs\n",
        "for epoch in range(30):\n",
        "    history = model.fit(X_train, y_train, epochs=1, batch_size=32, validation_data=(X_val, y_val), shuffle=False, verbose=1)\n",
        "\n",
        "    train_loss = history.history['loss'][0]\n",
        "    train_mae = history.history['mean_absolute_error'][0]\n",
        "\n",
        "    val_loss = history.history['val_loss'][0]\n",
        "    val_mae = history.history['val_mean_absolute_error'][0]\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"Continued Epoch {epoch+1}, Train Loss: {train_loss}, Train MAE: {train_mae}, Val Loss: {val_loss}, Val MAE: {val_mae}, Test Loss: {test_loss}, Test MAE: {test_mae}\")\n",
        "\n",
        "    prediction = model.predict(X_test)\n",
        "    mae_systolic = MeanAbsoluteError()\n",
        "    mae_systolic.update_state(y_test, prediction)\n",
        "    print(\"Mean absolute error for systolic is: \",mae_systolic.result().numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        },
        "id": "9LM1l9aU24ms",
        "outputId": "7bf32406-88c4-4c7f-a3b8-95e2dd822e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "438/438 [==============================] - 15s 34ms/step - loss: 11.1197 - mean_absolute_error: 2.6048 - val_loss: 22.2861 - val_mean_absolute_error: 3.9442\n",
            "Continued Epoch 1, Train Loss: 11.11965560913086, Train MAE: 2.604808807373047, Val Loss: 22.286102294921875, Val MAE: 3.9442245960235596, Test Loss: 37.27024841308594, Test MAE: 4.461658000946045\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  4.461658\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 10.8163 - mean_absolute_error: 2.5696 - val_loss: 206.6743 - val_mean_absolute_error: 13.5905\n",
            "Continued Epoch 2, Train Loss: 10.816266059875488, Train MAE: 2.5695512294769287, Val Loss: 206.6742706298828, Val MAE: 13.590544700622559, Test Loss: 250.49432373046875, Test MAE: 14.626826286315918\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  14.626828\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 10.7873 - mean_absolute_error: 2.5707 - val_loss: 33.7492 - val_mean_absolute_error: 5.0852\n",
            "Continued Epoch 3, Train Loss: 10.78734016418457, Train MAE: 2.570742130279541, Val Loss: 33.749168395996094, Val MAE: 5.085151195526123, Test Loss: 71.11781311035156, Test MAE: 7.245124340057373\n",
            "313/313 [==============================] - 3s 10ms/step\n",
            "Mean absolute error for systolic is:  7.2451234\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 10.5786 - mean_absolute_error: 2.5429 - val_loss: 104.8259 - val_mean_absolute_error: 9.8057\n",
            "Continued Epoch 4, Train Loss: 10.578558921813965, Train MAE: 2.5429184436798096, Val Loss: 104.82593536376953, Val MAE: 9.805662155151367, Test Loss: 159.32870483398438, Test MAE: 11.653082847595215\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for systolic is:  11.653085\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 10.6625 - mean_absolute_error: 2.5554 - val_loss: 19.9770 - val_mean_absolute_error: 3.8634\n",
            "Continued Epoch 5, Train Loss: 10.662518501281738, Train MAE: 2.5553982257843018, Val Loss: 19.97699546813965, Val MAE: 3.863356113433838, Test Loss: 70.95439910888672, Test MAE: 7.351831912994385\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  7.3518343\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 10.4768 - mean_absolute_error: 2.5346 - val_loss: 10.0040 - val_mean_absolute_error: 2.4751\n",
            "Continued Epoch 6, Train Loss: 10.476845741271973, Train MAE: 2.5346028804779053, Val Loss: 10.003973007202148, Val MAE: 2.4750521183013916, Test Loss: 33.53493118286133, Test MAE: 4.393366813659668\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for systolic is:  4.3933673\n",
            " 97/438 [=====>........................] - ETA: 10s - loss: 10.6769 - mean_absolute_error: 2.5950"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-0650ab13da52>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Continue training for 30 more epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(model, '/content/drive/MyDrive/Python work/sim_data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4pYYyxqFG80",
        "outputId": "af5b635a-d021-45d4-8cfa-152940e383a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YouyhQeFfLgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FCN_plus_systolic_model = model\n"
      ],
      "metadata": {
        "id": "G1A3yAet516E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_2vector(x, y, title='', xlabel='', ylabel='', color='blue', line_fit=False, mae=None):\n",
        "    plt.scatter(x, y, label='Systolic BP', color=color)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.grid(True)\n",
        "\n",
        "    if line_fit:\n",
        "        m, b = np.polyfit(x.flatten(), y.flatten(), 1)\n",
        "        plt.plot(x, m*x + b, color='red')\n",
        "\n",
        "    if mae is not None:\n",
        "        plt.legend([f'Best Fit Line\\nMAE = {mae:.2f}'])\n",
        "    else:\n",
        "        plt.legend()\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "eP8lajiW8vpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff6-x53aiHau",
        "outputId": "79499817-cde0-4ab5-e297-62e564590218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7a7d482c74f0>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = X_test[:, :, np.newaxis]\n",
        "y11 = FCN_plus_systolic_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEI-QgOWiJ7v",
        "outputId": "70428d31-5afa-4f69-d8d9-60ac08c50fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 9ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and labels\n",
        "X_train_full = train_data[:, :1000]\n",
        "y_train_full = train_data[:, -2]  # Only Systolic Blood Pressure\n",
        "X_test = test_data[:, :1000]\n",
        "y_test = test_data[:, -2]  # Only Systolic Blood Pressure"
      ],
      "metadata": {
        "id": "1g0UDDdYgCZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys_prediction = model.predict(X_test)\n",
        "#FCN_plus_systolic_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lds8LAvxgO2B",
        "outputId": "8c68e1a7-c1a2-44e1-9d06-56566e6a4174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 9ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FCN_PLUS Algorithm\n",
        "- For diastolic Blood pressure"
      ],
      "metadata": {
        "id": "MI7S0mUIXbBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.metrics import MeanAbsoluteError\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "# Separate features and labels\n",
        "X_train_full = train_data[:, :1000]\n",
        "y_train_full = train_data[:, -1]  # Only Diastolic Blood Pressure\n",
        "X_test = test_data[:, :1000]\n",
        "y_test = test_data[:, -1]  # Only Diastolic Blood Pressure\n",
        "\n",
        "# Split training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.3, random_state=42, shuffle=True)\n",
        "\n",
        "# Scale the features\n",
        "X_train_mean = np.mean(X_train, axis=1)\n",
        "X_train_mean = np.reshape(X_train_mean, (-1, 1))\n",
        "X_train_std = np.std(X_train, axis=1)\n",
        "X_train_std = np.reshape(X_train_std, (-1, 1))\n",
        "X_train = (X_train - X_train_mean) / X_train_std\n",
        "\n",
        "X_val_mean = np.mean(X_val, axis=1)\n",
        "X_val_mean = np.reshape(X_val_mean, (-1, 1))\n",
        "X_val_std = np.std(X_val, axis=1)\n",
        "X_val_std = np.reshape(X_val_std, (-1, 1))\n",
        "X_val = (X_val - X_val_mean) / X_val_std\n",
        "\n",
        "X_test_mean = np.mean(X_test, axis=1)\n",
        "X_test_mean = np.reshape(X_test_mean, (-1, 1))\n",
        "X_test_std = np.std(X_test, axis=1)\n",
        "X_test_std = np.reshape(X_test_std, (-1, 1))\n",
        "X_test = (X_test - X_test_mean) / X_test_std\n",
        "\n",
        "# Reshape data for FCN_PLUS\n",
        "X_train = X_train[:, :, np.newaxis]\n",
        "X_val = X_val[:, :, np.newaxis]\n",
        "X_test = X_test[:, :, np.newaxis]\n",
        "\n",
        "# Build the FCN_PLUS model\n",
        "diastolic_model = models.Sequential([\n",
        "    layers.Input(shape=(X_train.shape[1], 1)),\n",
        "    layers.Conv1D(filters=128, kernel_size=8, padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Conv1D(filters=256, kernel_size=5, padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Conv1D(filters=128, kernel_size=3, padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.GlobalAveragePooling1D(),\n",
        "    layers.Dense(1)  # Single output node for Systolic Blood Pressure\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "diastolic_model.compile(optimizer='adam', loss='mse', metrics=[MeanAbsoluteError()])\n",
        "\n",
        "# Train the model for 50 epochs and capture loss after each epoch\n",
        "for epoch in range(50):\n",
        "    history = diastolic_model.fit(X_train, y_train, epochs=1, batch_size=32, validation_data=(X_val, y_val), shuffle=False, verbose=1)\n",
        "\n",
        "    train_loss = history.history['loss'][0]\n",
        "    train_mae = history.history['mean_absolute_error'][0]\n",
        "\n",
        "    val_loss = history.history['val_loss'][0]\n",
        "    val_mae = history.history['val_mean_absolute_error'][0]\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_mae = diastolic_model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}, Train MAE: {train_mae}, Val Loss: {val_loss}, Val MAE: {val_mae}, Test Loss: {test_loss}, Test MAE: {test_mae}\")\n",
        "    prediction = diastolic_model.predict(X_test)\n",
        "    mae_diastolic = MeanAbsoluteError()\n",
        "    mae_diastolic.update_state(y_test, prediction)\n",
        "    print(\"Mean absolute error for diastolic is: \",mae_diastolic.result().numpy())\n",
        "# mae = mean_absolute_error(prediction,y_test)\n",
        "# mae1 = np.mean(np.abs(y_test - prediction))\n",
        "# print(f\"Mean absolute error for systolic BP is: \", mae1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-6pOxyZ58Bi",
        "outputId": "54450c0f-f4c4-42a1-e94a-4647aad6428b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "438/438 [==============================] - 18s 35ms/step - loss: 3676.8303 - mean_absolute_error: 57.5325 - val_loss: 1163.8890 - val_mean_absolute_error: 32.1401\n",
            "Epoch 1, Train Loss: 3676.830322265625, Train MAE: 57.53253173828125, Val Loss: 1163.8890380859375, Val MAE: 32.14011764526367, Test Loss: 1159.1810302734375, Test MAE: 32.061683654785156\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for diastolic is:  32.06168\n",
            "438/438 [==============================] - 15s 34ms/step - loss: 236.2621 - mean_absolute_error: 12.0338 - val_loss: 1124.6627 - val_mean_absolute_error: 32.3397\n",
            "Epoch 2, Train Loss: 236.26206970214844, Train MAE: 12.033808708190918, Val Loss: 1124.6627197265625, Val MAE: 32.3397102355957, Test Loss: 1017.6702270507812, Test MAE: 30.62932777404785\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for diastolic is:  30.629332\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 44.7271 - mean_absolute_error: 5.3038 - val_loss: 1219.9447 - val_mean_absolute_error: 34.0227\n",
            "Epoch 3, Train Loss: 44.727088928222656, Train MAE: 5.303776741027832, Val Loss: 1219.9447021484375, Val MAE: 34.022682189941406, Test Loss: 892.7802734375, Test MAE: 28.871166229248047\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  28.871162\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 20.6298 - mean_absolute_error: 3.4576 - val_loss: 398.5990 - val_mean_absolute_error: 19.4793\n",
            "Epoch 4, Train Loss: 20.62979507446289, Train MAE: 3.457592010498047, Val Loss: 398.5989685058594, Val MAE: 19.47932243347168, Test Loss: 255.71499633789062, Test MAE: 15.038957595825195\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  15.038955\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 17.3963 - mean_absolute_error: 3.1774 - val_loss: 156.6024 - val_mean_absolute_error: 11.9532\n",
            "Epoch 5, Train Loss: 17.396331787109375, Train MAE: 3.177446126937866, Val Loss: 156.60244750976562, Val MAE: 11.953230857849121, Test Loss: 94.9393081665039, Test MAE: 8.68421459197998\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  8.684219\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 15.9487 - mean_absolute_error: 3.0490 - val_loss: 297.1766 - val_mean_absolute_error: 16.8186\n",
            "Epoch 6, Train Loss: 15.948741912841797, Train MAE: 3.048980474472046, Val Loss: 297.1766052246094, Val MAE: 16.818593978881836, Test Loss: 190.65966796875, Test MAE: 12.763153076171875\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  12.763153\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 14.9672 - mean_absolute_error: 2.9606 - val_loss: 120.7266 - val_mean_absolute_error: 10.4361\n",
            "Epoch 7, Train Loss: 14.967153549194336, Train MAE: 2.9605987071990967, Val Loss: 120.72661590576172, Val MAE: 10.436128616333008, Test Loss: 76.82315063476562, Test MAE: 7.672556400299072\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  7.672552\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 14.3175 - mean_absolute_error: 2.9004 - val_loss: 77.5760 - val_mean_absolute_error: 8.1216\n",
            "Epoch 8, Train Loss: 14.317462921142578, Train MAE: 2.9003756046295166, Val Loss: 77.5759506225586, Val MAE: 8.121647834777832, Test Loss: 43.677032470703125, Test MAE: 5.526727676391602\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  5.5267286\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 13.7095 - mean_absolute_error: 2.8418 - val_loss: 113.7195 - val_mean_absolute_error: 10.1439\n",
            "Epoch 9, Train Loss: 13.70946979522705, Train MAE: 2.841777801513672, Val Loss: 113.71952819824219, Val MAE: 10.143851280212402, Test Loss: 66.8581771850586, Test MAE: 7.068482875823975\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  7.068483\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 13.2235 - mean_absolute_error: 2.7929 - val_loss: 64.4999 - val_mean_absolute_error: 7.4143\n",
            "Epoch 10, Train Loss: 13.223464965820312, Train MAE: 2.792893886566162, Val Loss: 64.49989318847656, Val MAE: 7.414273262023926, Test Loss: 42.52532958984375, Test MAE: 5.467103958129883\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  5.4671035\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 12.7963 - mean_absolute_error: 2.7488 - val_loss: 58.3320 - val_mean_absolute_error: 6.9884\n",
            "Epoch 11, Train Loss: 12.796292304992676, Train MAE: 2.7488417625427246, Val Loss: 58.332035064697266, Val MAE: 6.988368511199951, Test Loss: 35.97572708129883, Test MAE: 4.983354091644287\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for diastolic is:  4.9833546\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 12.3691 - mean_absolute_error: 2.7044 - val_loss: 159.6698 - val_mean_absolute_error: 12.0015\n",
            "Epoch 12, Train Loss: 12.369149208068848, Train MAE: 2.704393148422241, Val Loss: 159.66978454589844, Val MAE: 12.001521110534668, Test Loss: 89.2494125366211, Test MAE: 8.196699142456055\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  8.196703\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 11.9876 - mean_absolute_error: 2.6643 - val_loss: 96.1693 - val_mean_absolute_error: 9.2914\n",
            "Epoch 13, Train Loss: 11.987617492675781, Train MAE: 2.664259433746338, Val Loss: 96.1693115234375, Val MAE: 9.291363716125488, Test Loss: 60.96961975097656, Test MAE: 6.682236671447754\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  6.6822352\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 11.6233 - mean_absolute_error: 2.6234 - val_loss: 12.5818 - val_mean_absolute_error: 2.6447\n",
            "Epoch 14, Train Loss: 11.62325668334961, Train MAE: 2.623429298400879, Val Loss: 12.581777572631836, Val MAE: 2.644737720489502, Test Loss: 31.767749786376953, Test MAE: 4.107245922088623\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  4.107243\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 11.2849 - mean_absolute_error: 2.5869 - val_loss: 26.4322 - val_mean_absolute_error: 4.3892\n",
            "Epoch 15, Train Loss: 11.284933090209961, Train MAE: 2.586855173110962, Val Loss: 26.4322452545166, Val MAE: 4.389223098754883, Test Loss: 29.833711624145508, Test MAE: 4.229952812194824\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  4.2299523\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 10.9753 - mean_absolute_error: 2.5516 - val_loss: 21.9605 - val_mean_absolute_error: 3.8299\n",
            "Epoch 16, Train Loss: 10.975290298461914, Train MAE: 2.5516436100006104, Val Loss: 21.960468292236328, Val MAE: 3.8298563957214355, Test Loss: 29.76056480407715, Test MAE: 4.132045745849609\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  4.1320467\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 10.6988 - mean_absolute_error: 2.5210 - val_loss: 44.7060 - val_mean_absolute_error: 6.1039\n",
            "Epoch 17, Train Loss: 10.698847770690918, Train MAE: 2.52101469039917, Val Loss: 44.70600509643555, Val MAE: 6.103869915008545, Test Loss: 35.27790832519531, Test MAE: 4.8683271408081055\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  4.868329\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 10.4519 - mean_absolute_error: 2.4912 - val_loss: 50.4165 - val_mean_absolute_error: 6.2550\n",
            "Epoch 18, Train Loss: 10.451911926269531, Train MAE: 2.4911534786224365, Val Loss: 50.41650390625, Val MAE: 6.255016326904297, Test Loss: 37.102787017822266, Test MAE: 4.903591156005859\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  4.9035907\n",
            "438/438 [==============================] - 16s 35ms/step - loss: 10.2250 - mean_absolute_error: 2.4623 - val_loss: 17.6126 - val_mean_absolute_error: 3.2768\n",
            "Epoch 19, Train Loss: 10.225020408630371, Train MAE: 2.462311267852783, Val Loss: 17.612642288208008, Val MAE: 3.276787757873535, Test Loss: 33.825443267822266, Test MAE: 4.29164981842041\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  4.2916493\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 9.9640 - mean_absolute_error: 2.4321 - val_loss: 30.7373 - val_mean_absolute_error: 4.7192\n",
            "Epoch 20, Train Loss: 9.963958740234375, Train MAE: 2.4320809841156006, Val Loss: 30.737340927124023, Val MAE: 4.7191972732543945, Test Loss: 34.810787200927734, Test MAE: 4.566534519195557\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  4.5665374\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 9.7636 - mean_absolute_error: 2.4078 - val_loss: 8.0615 - val_mean_absolute_error: 2.0627\n",
            "Epoch 21, Train Loss: 9.763559341430664, Train MAE: 2.407757043838501, Val Loss: 8.061467170715332, Val MAE: 2.062694549560547, Test Loss: 37.83872985839844, Test MAE: 4.375044345855713\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  4.375046\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 9.4976 - mean_absolute_error: 2.3743 - val_loss: 6.4976 - val_mean_absolute_error: 1.9833\n",
            "Epoch 22, Train Loss: 9.497600555419922, Train MAE: 2.374281167984009, Val Loss: 6.497560024261475, Val MAE: 1.983322262763977, Test Loss: 50.17518997192383, Test MAE: 5.199286460876465\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  5.19929\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 9.2995 - mean_absolute_error: 2.3489 - val_loss: 16.3751 - val_mean_absolute_error: 3.2658\n",
            "Epoch 23, Train Loss: 9.299485206604004, Train MAE: 2.3489227294921875, Val Loss: 16.375097274780273, Val MAE: 3.2658092975616455, Test Loss: 33.585872650146484, Test MAE: 4.210690021514893\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for diastolic is:  4.2106905\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 9.0513 - mean_absolute_error: 2.3177 - val_loss: 9.5484 - val_mean_absolute_error: 2.2418\n",
            "Epoch 24, Train Loss: 9.051261901855469, Train MAE: 2.3176839351654053, Val Loss: 9.548447608947754, Val MAE: 2.2418062686920166, Test Loss: 40.33620071411133, Test MAE: 4.496884822845459\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  4.4968853\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 8.8445 - mean_absolute_error: 2.2912 - val_loss: 7.6211 - val_mean_absolute_error: 2.2249\n",
            "Epoch 25, Train Loss: 8.844484329223633, Train MAE: 2.291217565536499, Val Loss: 7.621078014373779, Val MAE: 2.2248923778533936, Test Loss: 61.458011627197266, Test MAE: 5.954394340515137\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for diastolic is:  5.9543943\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 8.6422 - mean_absolute_error: 2.2668 - val_loss: 9.4412 - val_mean_absolute_error: 2.5646\n",
            "Epoch 26, Train Loss: 8.642234802246094, Train MAE: 2.2668282985687256, Val Loss: 9.44115924835205, Val MAE: 2.5646169185638428, Test Loss: 70.95359802246094, Test MAE: 6.562260150909424\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  6.562261\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 8.5169 - mean_absolute_error: 2.2480 - val_loss: 11.4588 - val_mean_absolute_error: 2.5536\n",
            "Epoch 27, Train Loss: 8.51690673828125, Train MAE: 2.2479538917541504, Val Loss: 11.458762168884277, Val MAE: 2.553605079650879, Test Loss: 39.7584342956543, Test MAE: 4.499030113220215\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  4.4990315\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 8.2688 - mean_absolute_error: 2.2177 - val_loss: 8.0634 - val_mean_absolute_error: 2.3402\n",
            "Epoch 28, Train Loss: 8.26884651184082, Train MAE: 2.2177116870880127, Val Loss: 8.063414573669434, Val MAE: 2.340200424194336, Test Loss: 66.79013061523438, Test MAE: 6.2416157722473145\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  6.241617\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 8.1960 - mean_absolute_error: 2.2080 - val_loss: 28.8391 - val_mean_absolute_error: 4.9705\n",
            "Epoch 29, Train Loss: 8.195999145507812, Train MAE: 2.208008289337158, Val Loss: 28.839122772216797, Val MAE: 4.970521926879883, Test Loss: 120.387939453125, Test MAE: 9.430365562438965\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  9.430364\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 7.9994 - mean_absolute_error: 2.1804 - val_loss: 17.7838 - val_mean_absolute_error: 3.7773\n",
            "Epoch 30, Train Loss: 7.999438285827637, Train MAE: 2.1803994178771973, Val Loss: 17.783823013305664, Val MAE: 3.7773027420043945, Test Loss: 97.23587799072266, Test MAE: 8.190427780151367\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  8.19043\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 7.8746 - mean_absolute_error: 2.1613 - val_loss: 7.3987 - val_mean_absolute_error: 2.2280\n",
            "Epoch 31, Train Loss: 7.874632835388184, Train MAE: 2.1613192558288574, Val Loss: 7.398689270019531, Val MAE: 2.227975845336914, Test Loss: 64.97586059570312, Test MAE: 6.114907264709473\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  6.114907\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 7.7006 - mean_absolute_error: 2.1415 - val_loss: 38.8322 - val_mean_absolute_error: 5.8824\n",
            "Epoch 32, Train Loss: 7.700559616088867, Train MAE: 2.1415019035339355, Val Loss: 38.8321647644043, Val MAE: 5.88235330581665, Test Loss: 133.72787475585938, Test MAE: 10.196820259094238\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  10.196822\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 7.5331 - mean_absolute_error: 2.1183 - val_loss: 14.7210 - val_mean_absolute_error: 3.4023\n",
            "Epoch 33, Train Loss: 7.533114433288574, Train MAE: 2.118314504623413, Val Loss: 14.721016883850098, Val MAE: 3.4023234844207764, Test Loss: 85.51017761230469, Test MAE: 7.423714637756348\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  7.4237156\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 7.3870 - mean_absolute_error: 2.0964 - val_loss: 24.0081 - val_mean_absolute_error: 4.5160\n",
            "Epoch 34, Train Loss: 7.386998653411865, Train MAE: 2.096395492553711, Val Loss: 24.008075714111328, Val MAE: 4.5160369873046875, Test Loss: 103.76554870605469, Test MAE: 8.590022087097168\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for diastolic is:  8.590025\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 7.3239 - mean_absolute_error: 2.0861 - val_loss: 26.1169 - val_mean_absolute_error: 4.7376\n",
            "Epoch 35, Train Loss: 7.323907852172852, Train MAE: 2.086064100265503, Val Loss: 26.11686897277832, Val MAE: 4.737612724304199, Test Loss: 110.06655883789062, Test MAE: 8.909523010253906\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  8.909525\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 7.1696 - mean_absolute_error: 2.0643 - val_loss: 36.5053 - val_mean_absolute_error: 5.7152\n",
            "Epoch 36, Train Loss: 7.169597625732422, Train MAE: 2.064340353012085, Val Loss: 36.505306243896484, Val MAE: 5.7151641845703125, Test Loss: 124.32661437988281, Test MAE: 9.725469589233398\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  9.7254715\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 6.9993 - mean_absolute_error: 2.0417 - val_loss: 43.4414 - val_mean_absolute_error: 6.2768\n",
            "Epoch 37, Train Loss: 6.999335289001465, Train MAE: 2.041653633117676, Val Loss: 43.4413948059082, Val MAE: 6.276773452758789, Test Loss: 133.953857421875, Test MAE: 10.215200424194336\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  10.2151985\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 6.9164 - mean_absolute_error: 2.0282 - val_loss: 24.0698 - val_mean_absolute_error: 4.5350\n",
            "Epoch 38, Train Loss: 6.916357040405273, Train MAE: 2.028235673904419, Val Loss: 24.06978988647461, Val MAE: 4.535037994384766, Test Loss: 100.8154525756836, Test MAE: 8.421923637390137\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for diastolic is:  8.421922\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 6.7607 - mean_absolute_error: 2.0062 - val_loss: 36.7091 - val_mean_absolute_error: 5.7411\n",
            "Epoch 39, Train Loss: 6.760739326477051, Train MAE: 2.0062098503112793, Val Loss: 36.70906066894531, Val MAE: 5.741098403930664, Test Loss: 122.78882598876953, Test MAE: 9.629719734191895\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for diastolic is:  9.629717\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 6.6616 - mean_absolute_error: 1.9911 - val_loss: 21.6309 - val_mean_absolute_error: 4.2726\n",
            "Epoch 40, Train Loss: 6.661633491516113, Train MAE: 1.991087555885315, Val Loss: 21.630889892578125, Val MAE: 4.272599697113037, Test Loss: 90.64488220214844, Test MAE: 7.803871154785156\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  7.8038735\n",
            "438/438 [==============================] - 49s 112ms/step - loss: 6.6679 - mean_absolute_error: 1.9939 - val_loss: 36.8137 - val_mean_absolute_error: 5.7527\n",
            "Epoch 41, Train Loss: 6.667858600616455, Train MAE: 1.9938552379608154, Val Loss: 36.813716888427734, Val MAE: 5.752705097198486, Test Loss: 123.84932708740234, Test MAE: 9.775911331176758\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  9.775911\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 6.4901 - mean_absolute_error: 1.9658 - val_loss: 63.0523 - val_mean_absolute_error: 7.6857\n",
            "Epoch 42, Train Loss: 6.490138530731201, Train MAE: 1.965789794921875, Val Loss: 63.052345275878906, Val MAE: 7.685669422149658, Test Loss: 159.64625549316406, Test MAE: 11.421138763427734\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  11.421138\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 6.4430 - mean_absolute_error: 1.9571 - val_loss: 21.1799 - val_mean_absolute_error: 4.2076\n",
            "Epoch 43, Train Loss: 6.4430437088012695, Train MAE: 1.9570503234863281, Val Loss: 21.179866790771484, Val MAE: 4.2075910568237305, Test Loss: 86.4240493774414, Test MAE: 7.564990043640137\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  7.5649915\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 6.3487 - mean_absolute_error: 1.9457 - val_loss: 15.5825 - val_mean_absolute_error: 3.4709\n",
            "Epoch 44, Train Loss: 6.34871244430542, Train MAE: 1.9457058906555176, Val Loss: 15.582545280456543, Val MAE: 3.470914363861084, Test Loss: 65.88736724853516, Test MAE: 6.253210067749023\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  6.253209\n",
            "438/438 [==============================] - 17s 38ms/step - loss: 6.2035 - mean_absolute_error: 1.9237 - val_loss: 47.6766 - val_mean_absolute_error: 6.6289\n",
            "Epoch 45, Train Loss: 6.20348596572876, Train MAE: 1.9236971139907837, Val Loss: 47.67659378051758, Val MAE: 6.628945350646973, Test Loss: 138.84910583496094, Test MAE: 10.477560997009277\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  10.477563\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 6.1905 - mean_absolute_error: 1.9221 - val_loss: 42.0949 - val_mean_absolute_error: 6.2060\n",
            "Epoch 46, Train Loss: 6.190489292144775, Train MAE: 1.9221076965332031, Val Loss: 42.09489440917969, Val MAE: 6.206040859222412, Test Loss: 127.24668884277344, Test MAE: 9.914961814880371\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  9.914966\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 6.1389 - mean_absolute_error: 1.9160 - val_loss: 76.1845 - val_mean_absolute_error: 8.5100\n",
            "Epoch 47, Train Loss: 6.138854503631592, Train MAE: 1.915987253189087, Val Loss: 76.18453216552734, Val MAE: 8.509963035583496, Test Loss: 184.86476135253906, Test MAE: 12.471063613891602\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  12.4710655\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 6.2417 - mean_absolute_error: 1.9271 - val_loss: 9.9273 - val_mean_absolute_error: 2.7353\n",
            "Epoch 48, Train Loss: 6.241732597351074, Train MAE: 1.9270994663238525, Val Loss: 9.92732048034668, Val MAE: 2.735311508178711, Test Loss: 70.08014678955078, Test MAE: 6.4158711433410645\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  6.415872\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 6.1152 - mean_absolute_error: 1.9092 - val_loss: 34.7864 - val_mean_absolute_error: 5.6061\n",
            "Epoch 49, Train Loss: 6.115207195281982, Train MAE: 1.9092414379119873, Val Loss: 34.78639221191406, Val MAE: 5.606141090393066, Test Loss: 123.36004638671875, Test MAE: 9.622652053833008\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  9.622649\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 5.9571 - mean_absolute_error: 1.8853 - val_loss: 6.6979 - val_mean_absolute_error: 2.0919\n",
            "Epoch 50, Train Loss: 5.957058429718018, Train MAE: 1.88530695438385, Val Loss: 6.697898864746094, Val MAE: 2.0918796062469482, Test Loss: 50.85930633544922, Test MAE: 5.038910388946533\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  5.0389104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FCN_PLUS_diastolic_model = diastolic_model"
      ],
      "metadata": {
        "id": "E16xrHQfIc2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(model, '/content/drive/MyDrive/Python work/sim_data/FCN_PLUS_diastolic_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_ILJysOIZBg",
        "outputId": "816e2793-1ee4-48ba-a2da-10e3c2114074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FCN_PLUS_diastolic_model_50e = diastolic_model"
      ],
      "metadata": {
        "id": "_aF5PTSxI5rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(20):\n",
        "    history = diastolic_model.fit(X_train, y_train, epochs=1, batch_size=32, validation_data=(X_val, y_val), shuffle=False, verbose=1)\n",
        "\n",
        "    train_loss = history.history['loss'][0]\n",
        "    train_mae = history.history['mean_absolute_error'][0]\n",
        "\n",
        "    val_loss = history.history['val_loss'][0]\n",
        "    val_mae = history.history['val_mean_absolute_error'][0]\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_mae = diastolic_model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}, Train MAE: {train_mae}, Val Loss: {val_loss}, Val MAE: {val_mae}, Test Loss: {test_loss}, Test MAE: {test_mae}\")\n",
        "    prediction = diastolic_model.predict(X_test)\n",
        "    mae_diastolic = MeanAbsoluteError()\n",
        "    mae_diastolic.update_state(y_test, prediction)\n",
        "    print(\"Mean absolute error for diastolic is: \",mae_diastolic.result().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51UnXpPPJxLx",
        "outputId": "8c03677e-74f4-42f2-f398-55ba23224907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "438/438 [==============================] - 17s 38ms/step - loss: 5.8704 - mean_absolute_error: 1.8735 - val_loss: 10.4573 - val_mean_absolute_error: 2.7679\n",
            "Epoch 1, Train Loss: 5.87044095993042, Train MAE: 1.8734914064407349, Val Loss: 10.457270622253418, Val MAE: 2.7679078578948975, Test Loss: 60.415199279785156, Test MAE: 5.693321228027344\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  5.6933208\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 5.8177 - mean_absolute_error: 1.8657 - val_loss: 5.0817 - val_mean_absolute_error: 1.7603\n",
            "Epoch 2, Train Loss: 5.8176984786987305, Train MAE: 1.8656898736953735, Val Loss: 5.081676483154297, Val MAE: 1.760340929031372, Test Loss: 39.853973388671875, Test MAE: 4.22880744934082\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for diastolic is:  4.228807\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 5.7161 - mean_absolute_error: 1.8492 - val_loss: 9.1557 - val_mean_absolute_error: 2.5731\n",
            "Epoch 3, Train Loss: 5.716125965118408, Train MAE: 1.8491655588150024, Val Loss: 9.15573787689209, Val MAE: 2.5730741024017334, Test Loss: 61.08107376098633, Test MAE: 5.792394161224365\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for diastolic is:  5.792395\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 5.6359 - mean_absolute_error: 1.8367 - val_loss: 15.6486 - val_mean_absolute_error: 3.5252\n",
            "Epoch 4, Train Loss: 5.635907173156738, Train MAE: 1.8366913795471191, Val Loss: 15.648615837097168, Val MAE: 3.525158643722534, Test Loss: 72.047607421875, Test MAE: 6.603603839874268\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for diastolic is:  6.603606\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 5.6568 - mean_absolute_error: 1.8431 - val_loss: 11.5207 - val_mean_absolute_error: 2.9289\n",
            "Epoch 5, Train Loss: 5.656813144683838, Train MAE: 1.8431158065795898, Val Loss: 11.520661354064941, Val MAE: 2.9289462566375732, Test Loss: 58.669151306152344, Test MAE: 5.675145149230957\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  5.675146\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 5.5515 - mean_absolute_error: 1.8241 - val_loss: 20.7821 - val_mean_absolute_error: 4.1676\n",
            "Epoch 6, Train Loss: 5.551479816436768, Train MAE: 1.8240517377853394, Val Loss: 20.7820987701416, Val MAE: 4.167618274688721, Test Loss: 83.59233856201172, Test MAE: 7.362400054931641\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  7.3623977\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 5.4898 - mean_absolute_error: 1.8152 - val_loss: 38.5688 - val_mean_absolute_error: 5.9259\n",
            "Epoch 7, Train Loss: 5.489789009094238, Train MAE: 1.8152159452438354, Val Loss: 38.568809509277344, Val MAE: 5.925907135009766, Test Loss: 122.02351379394531, Test MAE: 9.64410400390625\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  9.644106\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 5.4466 - mean_absolute_error: 1.8079 - val_loss: 38.5929 - val_mean_absolute_error: 5.9314\n",
            "Epoch 8, Train Loss: 5.446587085723877, Train MAE: 1.8079160451889038, Val Loss: 38.5928840637207, Val MAE: 5.931419849395752, Test Loss: 115.21627807617188, Test MAE: 9.308250427246094\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  9.308256\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 5.4819 - mean_absolute_error: 1.8115 - val_loss: 24.3710 - val_mean_absolute_error: 4.6090\n",
            "Epoch 9, Train Loss: 5.481897354125977, Train MAE: 1.8115100860595703, Val Loss: 24.37103843688965, Val MAE: 4.609043598175049, Test Loss: 94.26583099365234, Test MAE: 8.013671875\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  8.01367\n",
            "438/438 [==============================] - 16s 35ms/step - loss: 5.3644 - mean_absolute_error: 1.7933 - val_loss: 31.0077 - val_mean_absolute_error: 5.2600\n",
            "Epoch 10, Train Loss: 5.364431858062744, Train MAE: 1.7932637929916382, Val Loss: 31.0076961517334, Val MAE: 5.259991645812988, Test Loss: 105.49283599853516, Test MAE: 8.712043762207031\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  8.712038\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 5.3330 - mean_absolute_error: 1.7893 - val_loss: 32.1907 - val_mean_absolute_error: 5.3557\n",
            "Epoch 11, Train Loss: 5.332993507385254, Train MAE: 1.7892508506774902, Val Loss: 32.19066619873047, Val MAE: 5.355716705322266, Test Loss: 105.06617736816406, Test MAE: 8.670129776000977\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  8.670125\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 5.2862 - mean_absolute_error: 1.7841 - val_loss: 22.7492 - val_mean_absolute_error: 4.4083\n",
            "Epoch 12, Train Loss: 5.286201000213623, Train MAE: 1.7840873003005981, Val Loss: 22.749237060546875, Val MAE: 4.408289432525635, Test Loss: 87.4111557006836, Test MAE: 7.649774074554443\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  7.649775\n",
            "438/438 [==============================] - 16s 35ms/step - loss: 5.2499 - mean_absolute_error: 1.7745 - val_loss: 17.8461 - val_mean_absolute_error: 3.8594\n",
            "Epoch 13, Train Loss: 5.24989652633667, Train MAE: 1.7744975090026855, Val Loss: 17.84610366821289, Val MAE: 3.859433650970459, Test Loss: 81.84916687011719, Test MAE: 7.208988189697266\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  7.208988\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 5.2026 - mean_absolute_error: 1.7668 - val_loss: 31.4985 - val_mean_absolute_error: 5.2985\n",
            "Epoch 14, Train Loss: 5.202578067779541, Train MAE: 1.7667523622512817, Val Loss: 31.49847984313965, Val MAE: 5.298525333404541, Test Loss: 104.6195068359375, Test MAE: 8.640729904174805\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for diastolic is:  8.640733\n",
            "438/438 [==============================] - 16s 38ms/step - loss: 5.1773 - mean_absolute_error: 1.7651 - val_loss: 43.6255 - val_mean_absolute_error: 6.3347\n",
            "Epoch 15, Train Loss: 5.177341461181641, Train MAE: 1.7651396989822388, Val Loss: 43.62550735473633, Val MAE: 6.334745407104492, Test Loss: 126.90882873535156, Test MAE: 9.832639694213867\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for diastolic is:  9.832643\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 5.1416 - mean_absolute_error: 1.7583 - val_loss: 29.6029 - val_mean_absolute_error: 5.0991\n",
            "Epoch 16, Train Loss: 5.141636371612549, Train MAE: 1.758349895477295, Val Loss: 29.602909088134766, Val MAE: 5.099126815795898, Test Loss: 94.90987396240234, Test MAE: 8.088578224182129\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  8.088575\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 5.1063 - mean_absolute_error: 1.7511 - val_loss: 32.9031 - val_mean_absolute_error: 5.4566\n",
            "Epoch 17, Train Loss: 5.106306552886963, Train MAE: 1.7511208057403564, Val Loss: 32.90314483642578, Val MAE: 5.456550598144531, Test Loss: 110.97396087646484, Test MAE: 8.965625762939453\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  8.965628\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 5.0926 - mean_absolute_error: 1.7491 - val_loss: 36.3858 - val_mean_absolute_error: 5.7274\n",
            "Epoch 18, Train Loss: 5.0925984382629395, Train MAE: 1.7491075992584229, Val Loss: 36.38576889038086, Val MAE: 5.7273664474487305, Test Loss: 109.63480377197266, Test MAE: 8.941550254821777\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  8.941546\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 5.0230 - mean_absolute_error: 1.7380 - val_loss: 11.6631 - val_mean_absolute_error: 2.8680\n",
            "Epoch 19, Train Loss: 5.0230302810668945, Train MAE: 1.7380074262619019, Val Loss: 11.663100242614746, Val MAE: 2.8680455684661865, Test Loss: 32.54322052001953, Test MAE: 4.066777229309082\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for diastolic is:  4.066779\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 5.0015 - mean_absolute_error: 1.7346 - val_loss: 47.9552 - val_mean_absolute_error: 6.6518\n",
            "Epoch 20, Train Loss: 5.001451015472412, Train MAE: 1.7346117496490479, Val Loss: 47.95524978637695, Val MAE: 6.651821613311768, Test Loss: 129.7930145263672, Test MAE: 10.022144317626953\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  10.022151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    history = diastolic_model.fit(X_train, y_train, epochs=1, batch_size=32, validation_data=(X_val, y_val), shuffle=False, verbose=1)\n",
        "\n",
        "    train_loss = history.history['loss'][0]\n",
        "    train_mae = history.history['mean_absolute_error'][0]\n",
        "\n",
        "    val_loss = history.history['val_loss'][0]\n",
        "    val_mae = history.history['val_mean_absolute_error'][0]\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_mae = diastolic_model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}, Train MAE: {train_mae}, Val Loss: {val_loss}, Val MAE: {val_mae}, Test Loss: {test_loss}, Test MAE: {test_mae}\")\n",
        "    prediction = diastolic_model.predict(X_test)\n",
        "    mae_diastolic = MeanAbsoluteError()\n",
        "    mae_diastolic.update_state(y_test, prediction)\n",
        "    print(\"Mean absolute error for diastolic is: \",mae_diastolic.result().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWIraWIjKS-J",
        "outputId": "4f0b93de-9f5c-486f-bf68-7c65de0b493e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "438/438 [==============================] - 16s 36ms/step - loss: 4.8079 - mean_absolute_error: 1.7028 - val_loss: 13.1295 - val_mean_absolute_error: 3.0711\n",
            "Epoch 1, Train Loss: 4.807898998260498, Train MAE: 1.7027604579925537, Val Loss: 13.129457473754883, Val MAE: 3.0710628032684326, Test Loss: 58.838138580322266, Test MAE: 5.606288909912109\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  5.6062865\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 4.7687 - mean_absolute_error: 1.6953 - val_loss: 22.0254 - val_mean_absolute_error: 4.2754\n",
            "Epoch 2, Train Loss: 4.768712043762207, Train MAE: 1.695253610610962, Val Loss: 22.02543830871582, Val MAE: 4.275394439697266, Test Loss: 81.69019317626953, Test MAE: 7.235698223114014\n",
            "313/313 [==============================] - 3s 8ms/step\n",
            "Mean absolute error for diastolic is:  7.235697\n",
            "438/438 [==============================] - 16s 37ms/step - loss: 4.7504 - mean_absolute_error: 1.6916 - val_loss: 17.1173 - val_mean_absolute_error: 3.7012\n",
            "Epoch 3, Train Loss: 4.750396251678467, Train MAE: 1.6915695667266846, Val Loss: 17.117258071899414, Val MAE: 3.701235055923462, Test Loss: 73.38111114501953, Test MAE: 6.625276565551758\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  6.625275\n",
            "438/438 [==============================] - 16s 36ms/step - loss: 4.7505 - mean_absolute_error: 1.6900 - val_loss: 15.5868 - val_mean_absolute_error: 3.5312\n",
            "Epoch 4, Train Loss: 4.750468730926514, Train MAE: 1.690024733543396, Val Loss: 15.586810111999512, Val MAE: 3.5312271118164062, Test Loss: 77.75324249267578, Test MAE: 6.817440032958984\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  6.8174405\n",
            "438/438 [==============================] - 17s 38ms/step - loss: 4.7560 - mean_absolute_error: 1.6917 - val_loss: 22.3667 - val_mean_absolute_error: 4.3595\n",
            "Epoch 5, Train Loss: 4.7559814453125, Train MAE: 1.691741943359375, Val Loss: 22.3666934967041, Val MAE: 4.359528541564941, Test Loss: 89.64593505859375, Test MAE: 7.669903755187988\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  7.6699014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(20):\n",
        "    history = diastolic_model.fit(X_train, y_train, epochs=1, batch_size=32, validation_data=(X_val, y_val), shuffle=False, verbose=1)\n",
        "\n",
        "    train_loss = history.history['loss'][0]\n",
        "    train_mae = history.history['mean_absolute_error'][0]\n",
        "\n",
        "    val_loss = history.history['val_loss'][0]\n",
        "    val_mae = history.history['val_mean_absolute_error'][0]\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss, test_mae = diastolic_model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}, Train MAE: {train_mae}, Val Loss: {val_loss}, Val MAE: {val_mae}, Test Loss: {test_loss}, Test MAE: {test_mae}\")\n",
        "    prediction = diastolic_model.predict(X_test)\n",
        "    mae_diastolic = MeanAbsoluteError()\n",
        "    mae_diastolic.update_state(y_test, prediction)\n",
        "    print(\"Mean absolute error for diastolic is: \",mae_diastolic.result().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "gXmp1pS5OZYF",
        "outputId": "1bb9623b-62b3-483e-c17b-152ddb2e2193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "438/438 [==============================] - 17s 38ms/step - loss: 4.7568 - mean_absolute_error: 1.6928 - val_loss: 26.0947 - val_mean_absolute_error: 4.7858\n",
            "Epoch 1, Train Loss: 4.756789684295654, Train MAE: 1.6928054094314575, Val Loss: 26.094745635986328, Val MAE: 4.785771369934082, Test Loss: 96.88839721679688, Test MAE: 8.121363639831543\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  8.1213665\n",
            "438/438 [==============================] - 17s 38ms/step - loss: 4.6637 - mean_absolute_error: 1.6756 - val_loss: 14.7703 - val_mean_absolute_error: 3.4571\n",
            "Epoch 2, Train Loss: 4.663681983947754, Train MAE: 1.6756004095077515, Val Loss: 14.770330429077148, Val MAE: 3.457101583480835, Test Loss: 75.51539611816406, Test MAE: 6.676780700683594\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  6.676781\n",
            "438/438 [==============================] - 15s 35ms/step - loss: 4.6336 - mean_absolute_error: 1.6714 - val_loss: 5.6603 - val_mean_absolute_error: 1.8649\n",
            "Epoch 3, Train Loss: 4.633594512939453, Train MAE: 1.6714046001434326, Val Loss: 5.660263538360596, Val MAE: 1.8649028539657593, Test Loss: 44.52223587036133, Test MAE: 4.386704921722412\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "Mean absolute error for diastolic is:  4.3867064\n",
            "119/438 [=======>......................] - ETA: 10s - loss: 4.4676 - mean_absolute_error: 1.6557"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-af1499ceac25>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiastolic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1689\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1692\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \"\"\"\n\u001b[1;32m   1159\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mean absolute error for diastolic is: \",mae_diastolic.result().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUMrwQtZO1cz",
        "outputId": "3bac67f8-9dc6-4f9d-bfe2-4096fdd24a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute error for diastolic is:  4.3867064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### After 75 epochs, this accuracy is acheived for diastolic BP and this is mean absolute error"
      ],
      "metadata": {
        "id": "NnKNou86XpXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FCN_PLUS_diastolic_model_60e = diastolic_model"
      ],
      "metadata": {
        "id": "-crPqt8BPAB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(model, '/content/drive/MyDrive/Python work/sim_data/FCN_PLUS_diastolic_model_60e')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3ze5rZAPHkL",
        "outputId": "466a5522-fc96-46bb-fa6a-9b18490fe5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85ixtJpxPskZ",
        "outputId": "f1b24cb7-8513-42c1-f01c-f131e7ae5a54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([83., 79., 73., ..., 88., 87., 69.])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FCN_PLUS_diastolic_model_60e.predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLZ4-0pTWm_h",
        "outputId": "b1a76e9f-80f1-4a5a-d4dc-fedb6340ea53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7a7d48bcd4e0>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae_diastolic.result().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Bv3syo_n3NN",
        "outputId": "d330d6d5-d0ab-4b20-903d-e400f9e9ff77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.3867064"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This is MAE for diastolic Blood pressure"
      ],
      "metadata": {
        "id": "GRvXNYsAZj5C"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mAYeCkq_ZnkG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}