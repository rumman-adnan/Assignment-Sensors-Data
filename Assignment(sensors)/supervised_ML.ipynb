{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 1006),\n",
       " (10000, 1006),\n",
       " array([-2.45845714e-07, -2.06162897e-07,  1.56348382e-06, ...,\n",
       "         1.90000000e+01,  9.10000000e+01,  9.50000000e+01]),\n",
       " array([-7.14960675e-08, -3.61296976e-08,  3.41059619e-07, ...,\n",
       "         1.10000000e+01,  1.72000000e+02,  8.30000000e+01]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import dataset\n",
    "train_data = np.load('simu_20000_0.1_90_140_train.npy')\n",
    "\n",
    "test_data = np.load('simu_10000_0.1_141_178_test.npy')\n",
    "\n",
    "# Display shapes and sample data\n",
    "train_shape, test_shape, train_data_sample, test_data_sample = train_data.shape, test_data.shape, train_data[0], test_data[0]\n",
    "# write print statement and show sample data\n",
    "#print(train_shape, test_shape, train_data_sample, test_data_sample)\n",
    "train_shape, test_shape, train_data_sample, test_data_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 1000), (20000,), (20000,), (10000, 1000), (10000,), (10000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data into input and outputs\n",
    "\n",
    "# For training data\n",
    "X_train = train_data[:, :1000]\n",
    "y_train_systolic = train_data[:, -2]\n",
    "y_train_diastolic = train_data[:, -1]\n",
    "\n",
    "# For test data\n",
    "X_test = test_data[:, :1000]\n",
    "y_test_systolic = test_data[:, -2]\n",
    "y_test_diastolic = test_data[:, -1]\n",
    "\n",
    "# Displaying shapes to verify the split and print statemnt\n",
    "#print(X_train.shape, y_train_systolic.shape, y_train_diastolic.shape, X_test.shape, y_test_systolic.shape, y_test_diastolic.shape)\n",
    "X_train.shape, y_train_systolic.shape, y_train_diastolic.shape, X_test.shape, y_test_systolic.shape, y_test_diastolic.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to reduce dimensionality\n",
    "pca = PCA(n_components=100)  # Reduce to 100 principal components\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Ridge Regression models for systolic and diastolic pressures\n",
    "ridge_systolic = Ridge(alpha=1.0)\n",
    "ridge_diastolic = Ridge(alpha=1.0)\n",
    "\n",
    "ridge_systolic.fit(X_train_pca, y_train_systolic)\n",
    "ridge_diastolic.fit(X_train_pca, y_train_diastolic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44.53694702295776, 10.205348634704755)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction of the te4st set\n",
    "y_predict_systolic = ridge_systolic.predict(X_test_pca)\n",
    "y_predict_diastolic = ridge_diastolic.predict(X_test_pca)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_systolic_ridge = ridge_systolic.predict(X_test_pca)\n",
    "y_pred_diastolic_ridge = ridge_diastolic.predict(X_test_pca)\n",
    "\n",
    "# Calculate the MAE for both systolic and diastolic predictions\n",
    "mae_systolic_ridge = mean_absolute_error(y_test_systolic, y_pred_systolic_ridge)\n",
    "mae_diastolic_ridge = mean_absolute_error(y_test_diastolic, y_pred_diastolic_ridge)\n",
    "\n",
    "mae_systolic_ridge, mae_diastolic_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These error values are higher than with Gradient Boosting, because Ridge Regression is a simpler model and we've also reduced the dimensionality of the data. However, the training time is significantly reduced with this approach.\n",
    "\n",
    "- To balance accuracy and training time, we experiment with different numbers of principal components in PCA or trying other dimensionality reduction techniques. \n",
    "- Using TensorFlow or other deep learning libraries, neural networks could potentially provide better accuracy without being overly time-consuming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25.27432752763387, 83.84633477096953)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Train Linear Regression models for systolic and diastolic pressures\n",
    "linreg_systolic = LinearRegression()\n",
    "linreg_diastolic = LinearRegression()\n",
    "\n",
    "linreg_systolic.fit(X_train, y_train_systolic)\n",
    "linreg_diastolic.fit(X_train, y_train_diastolic)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_systolic_linreg = linreg_systolic.predict(X_test)\n",
    "y_pred_diastolic_linreg = linreg_diastolic.predict(X_test)\n",
    "\n",
    "# Calculate the MAE for both systolic and diastolic predictions\n",
    "mae_systolic_linreg = mean_absolute_error(y_test_systolic, y_pred_systolic_linreg)\n",
    "mae_diastolic_linreg = mean_absolute_error(y_test_diastolic, y_pred_diastolic_linreg)\n",
    "\n",
    "mae_systolic_linreg, mae_diastolic_linreg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The error for the diastolic blood pressure is quite high compared to previous models. This suggests that the relationship between the input features and diastolic blood pressure might not be purely linear.\n",
    "\n",
    "- Linear regression model does provide a quick baseline. We can also explore other simple models, as mentioned. For example, Support Vector Machines (SVM) for regression can capture non-linearities without being as computationally intensive as Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36.243610709596666, 10.202642191617658)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Use a subset of the training data for faster results\n",
    "subset_indices = np.random.choice(X_train.shape[0], 5000, replace=False)\n",
    "X_train_subset = X_train[subset_indices]\n",
    "y_train_systolic_subset = y_train_systolic[subset_indices]\n",
    "y_train_diastolic_subset = y_train_diastolic[subset_indices]\n",
    "\n",
    "# Train SVR models for systolic and diastolic pressures\n",
    "svr_systolic = SVR(kernel='rbf', C=1.0, epsilon=0.2)\n",
    "svr_diastolic = SVR(kernel='rbf', C=1.0, epsilon=0.2)\n",
    "\n",
    "svr_systolic.fit(X_train_subset, y_train_systolic_subset)\n",
    "svr_diastolic.fit(X_train_subset, y_train_diastolic_subset)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_systolic_svr = svr_systolic.predict(X_test)\n",
    "y_pred_diastolic_svr = svr_diastolic.predict(X_test)\n",
    "\n",
    "# Calculate the MAE for both systolic and diastolic predictions\n",
    "mae_systolic_svr = mean_absolute_error(y_test_systolic, y_pred_systolic_svr)\n",
    "mae_diastolic_svr = mean_absolute_error(y_test_diastolic, y_pred_diastolic_svr)\n",
    "\n",
    "mae_systolic_svr, mae_diastolic_svr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.583030143282166, 48.70141800888808)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train SVR models with a linear kernel on the scaled data\n",
    "svr_systolic_linear = SVR(kernel='linear', C=1.0, epsilon=0.2)\n",
    "svr_diastolic_linear = SVR(kernel='linear', C=1.0, epsilon=0.2)\n",
    "\n",
    "# Using a subset of the training data for faster results\n",
    "svr_systolic_linear.fit(X_train_scaled[subset_indices], y_train_systolic_subset)\n",
    "svr_diastolic_linear.fit(X_train_scaled[subset_indices], y_train_diastolic_subset)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_systolic_svr_linear = svr_systolic_linear.predict(X_test_scaled)\n",
    "y_pred_diastolic_svr_linear = svr_diastolic_linear.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the MAE for both systolic and diastolic predictions\n",
    "mae_systolic_svr_linear = mean_absolute_error(y_test_systolic, y_pred_systolic_svr_linear)\n",
    "mae_diastolic_svr_linear = mean_absolute_error(y_test_diastolic, y_pred_diastolic_svr_linear)\n",
    "\n",
    "mae_systolic_svr_linear, mae_diastolic_svr_linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
