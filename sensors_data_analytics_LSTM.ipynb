{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyPb/DNb56/vjVHyYw5aQIVk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rumman-adnan/Assignment-Sensors-Data/blob/main/sensors_data_analytics_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkEHc5dGruuK",
        "outputId": "33027726-6dd2-4998-c95b-67a95743c27f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "nxp0WpF4r186"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.load('/content/drive/MyDrive/Python work/sim_data/simu_20000_0.1_90_140_train.npy')\n",
        "test_data = np.load('/content/drive/MyDrive/Python work/sim_data/simu_10000_0.1_141_178_test.npy')\n",
        "\n",
        "print(\"The shape of trained data is: \",train_data.shape)\n",
        "print(\"The shape of tested data is: \",test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFO0E7-wr7-Z",
        "outputId": "260b902d-df0f-47b7-ab00-26a369769a1d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of trained data is:  (20000, 1006)\n",
            "The shape of tested data is:  (10000, 1006)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction of features and targets\n",
        "\n",
        "# Training features and targets\n",
        "X_train_lstm = train_data[:, :1000]\n",
        "Y_train_lstm = train_data[:, -2:]\n",
        "\n",
        "# Testing features and targets\n",
        "X_test_lstm = test_data[:, :1000]\n",
        "Y_test_lstm = test_data[:, -2:]\n",
        "\n",
        "# Reshaping data for LSTM\n",
        "X_train_lstm = X_train_lstm.reshape(X_train_lstm.shape[0], X_train_lstm.shape[1], 1)\n",
        "X_test_lstm = X_test_lstm.reshape(X_test_lstm.shape[0], X_test_lstm.shape[1], 1)\n"
      ],
      "metadata": {
        "id": "ThtiMku-zujW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "\n",
        "# #\n",
        "# X_train_lstm = X_train_lstm.reshape(X_train_lstm.shape[0], X_train_lstm.shape[1], 1)\n",
        "# X_test_lstm = X_test_lstm.reshape(X_test_lstm.shape[0], X_test_lstm.shape[1], 1)\n",
        "\n",
        "\n",
        "# # Reshaping data for LSTM, Data shape is already suitable for LSTM: (batch_size, timesteps, features)\n",
        "# X_train_lstm = X_train_lstm.reshape(X_train_lstm.shape[0], X_train_lstm.shape[1], 1)\n",
        "# X_test_lstm = X_test_lstm.reshape(X_test_lstm.shape[0], X_test_lstm.shape[1], 1)\n",
        "\n",
        "# Model Creation\n",
        "model = Sequential()\n",
        "\n",
        "# Adding LSTM layer optimized for cuDNN\n",
        "model.add(LSTM(50, activation='tanh', recurrent_activation='sigmoid', input_shape=(X_train_lstm.shape[1], 1)))\n",
        "\n",
        "# Dense layers for regression\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(2))  # Two output units for S and D\n",
        "\n",
        "# Define optimizer and loss\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "# Custom training loop\n",
        "epochs = 500  # Maximum epochs\n",
        "batch_size = 32\n",
        "desired_mae = 3\n",
        "steps_per_epoch = len(X_train_lstm) // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nEpoch {}/{}\".format(epoch+1, epochs))\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Create a batch of data\n",
        "        X_batch = X_train_lstm[step*batch_size:(step+1)*batch_size]\n",
        "        Y_batch = Y_train_lstm[step*batch_size:(step+1)*batch_size]\n",
        "\n",
        "        # Forward pass\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = model(X_batch, training=True)\n",
        "            loss_value = loss_fn(Y_batch, predictions)\n",
        "\n",
        "        # Backward pass\n",
        "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Evaluate after each epoch\n",
        "    predictions = model(X_test_lstm)\n",
        "    mae_scores = mean_absolute_error(Y_test_lstm, predictions, multioutput='raw_values')\n",
        "    print(\"MAE after epoch {}: {}\".format(epoch+1, mae_scores))\n",
        "\n",
        "    # If desired MAE is achieved, stop training\n",
        "    if mae_scores[0] <= desired_mae and mae_scores[1] <= desired_mae:\n",
        "        print(\"Desired MAE achieved. Stopping training.\")\n",
        "        break\n"
      ],
      "metadata": {
        "id": "UGTzw3E6vQbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply Min Max Scaler"
      ],
      "metadata": {
        "id": "1KSO6TWH7aVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the scalers\n",
        "feature_scaler = MinMaxScaler()\n",
        "target_scaler = MinMaxScaler()\n",
        "\n",
        "# Scaling features\n",
        "X_train_scaled = feature_scaler.fit_transform(X_train_lstm.reshape(X_train_lstm.shape[0], X_train_lstm.shape[1]))\n",
        "X_test_scaled = feature_scaler.transform(X_test_lstm.reshape(X_test_lstm.shape[0], X_test_lstm.shape[1]))\n",
        "X_train_scaled = X_train_scaled.reshape(X_train_lstm.shape[0], X_train_lstm.shape[1], 1)\n",
        "X_test_scaled = X_test_scaled.reshape(X_test_lstm.shape[0], X_test_lstm.shape[1], 1)\n",
        "\n",
        "# Scaling targets\n",
        "Y_train_scaled = target_scaler.fit_transform(Y_train_lstm)\n",
        "Y_test_scaled = target_scaler.transform(Y_test_lstm)\n",
        "\n",
        "X_train_scaled.shape, X_test_scaled.shape, Y_train_scaled.shape, Y_test_scaled.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUWNcRInt1Zw",
        "outputId": "d79cb138-41a7-4d49-fdba-b5e55865cf46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20000, 1000, 1), (10000, 1000, 1), (20000, 2), (10000, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train LSTM Model"
      ],
      "metadata": {
        "id": "UlY7pzZs8IL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Define the LSTM model\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(50, activation='tanh', recurrent_activation='sigmoid', input_shape=(X_train_scaled.shape[1], 1)))\n",
        "model_lstm.add(Dense(50, activation='relu'))\n",
        "model_lstm.add(Dense(2))  # Two output units for S and D\n",
        "\n",
        "# Compiling the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_lstm.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "# Training the LSTM model\n",
        "desired_mae = 3\n",
        "best_mae = float('inf')\n",
        "patience = 10  # Number of epochs to wait if no improvement before stopping\n",
        "wait = 0\n",
        "\n",
        "for epoch in range(500):  # Maximum epochs\n",
        "    print(f\"\\nEpoch {epoch+1}/500\")\n",
        "\n",
        "    # Train the model\n",
        "    model_lstm.fit(X_train_scaled, Y_train_scaled, batch_size=32, epochs=1, verbose=1, validation_data=(X_test_scaled, Y_test_scaled))\n",
        "\n",
        "    # Evaluate the model's performance on the test set\n",
        "    predictions = model_lstm.predict(X_test_scaled)\n",
        "    mae_scores = mean_absolute_error(Y_test_scaled, predictions, multioutput='raw_values')\n",
        "    print(f\"Mean Absolute Error for S: {mae_scores[0]}, for D: {mae_scores[1]}\")\n",
        "\n",
        "    # Early stopping based on desired MAE\n",
        "    if mae_scores[0] <= desired_mae and mae_scores[1] <= desired_mae:\n",
        "        print(\"Desired MAE achieved. Stopping training.\")\n",
        "        break\n",
        "\n",
        "    # Implementing patience for early stopping\n",
        "    if mae_scores[0] < best_mae or mae_scores[1] < best_mae:\n",
        "        best_mae = min(mae_scores)\n",
        "        wait = 0\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(f\"MAE did not improve for {patience} consecutive epochs. Stopping training.\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e4BZTbSwvV3",
        "outputId": "3f1a157c-5c0d-49c4-9a2e-d4421cbdfe5b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/500\n",
            "625/625 [==============================] - 29s 35ms/step - loss: 0.0906 - val_loss: 0.4528\n",
            "313/313 [==============================] - 4s 12ms/step\n",
            "Mean Absolute Error for S: 0.8776830042492247, for D: 0.2555532025271651\n",
            "Desired MAE achieved. Stopping training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8k394KNNybW1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}